{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f97786",
   "metadata": {},
   "source": [
    "# NinaPro DB - 52-Class EMG Analysis (Movement Classes Only)\n",
    "\n",
    "This notebook provides a comprehensive analysis of the NinaPro Database (DB) EMG dataset, combining all three exercises (E1, E2, E3) across 10 subjects to create a unified 52-class movement classification dataset.\n",
    "\n",
    "**Note: The rest class has been completely removed from this analysis.**\n",
    "\n",
    "## Dataset Overview\n",
    "- **Database**: NinaPro DB\n",
    "- **Subjects**: 10 subjects (S1-S10)\n",
    "- **Exercises**: 3 exercises per subject\n",
    "  - E1: Basic finger movements (12 classes → Classes 0-11)\n",
    "  - E2: Hand configurations & wrist movements (17 classes → Classes 12-28)  \n",
    "  - E3: Grasping & functional movements (23 classes → Classes 29-51)\n",
    "- **Total Classes**: 52 movement classes only (0-51, rest class removed)\n",
    "- **EMG Channels**: 16 channels per subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b7916",
   "metadata": {},
   "source": [
    "## 1. Load EMG Data from NinaPro DB\n",
    "\n",
    "Load and combine EMG data from all exercises and subjects with proper class relabeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c060e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Load all three exercise files for all 10 subjects\n",
    "base_path = r'C:\\Users\\mspan\\Documents\\Code\\Bachelor\\NinaPro5'\n",
    "exercises = ['E1', 'E2', 'E3']\n",
    "subjects = range(1, 11)  # Subjects 1 to 10\n",
    "\n",
    "print(\"NinaPro DB - Combining All Exercises for All Subjects (52 Classes)\")\n",
    "print(\"Loading all exercise files for all subjects...\")\n",
    "print()\n",
    "\n",
    "all_subjects_data = {}\n",
    "\n",
    "# Load data from all subjects and exercises\n",
    "for subject in subjects:\n",
    "    subject_data = {}\n",
    "    for exercise in exercises:\n",
    "        file_path = f\"{base_path}\\\\s{subject}\\\\S{subject}_{exercise}_A1.mat\"\n",
    "        try:\n",
    "            data = sio.loadmat(file_path)\n",
    "            subject_data[exercise] = data\n",
    "            print(f\"Loaded S{subject}_{exercise}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "    \n",
    "    if subject_data:  # Only add if at least some data is loaded\n",
    "        all_subjects_data[f'S{subject}'] = subject_data\n",
    "\n",
    "print(f\"\\nLoaded data for {len(all_subjects_data)} subjects\")\n",
    "print()\n",
    "\n",
    "# Combine all exercises for all subjects with proper class relabeling\n",
    "print(\"Combining All Exercises For All Subjects\")\n",
    "\n",
    "# Strategy: Relabel classes to be sequential across exercises\n",
    "# E1: Classes 1-12 → Keep as 1-12\n",
    "# E2: Classes 1-17 → Relabel as 13-29 (12 + 1-17)\n",
    "# E3: Classes 1-23 → Relabel as 30-52 (29 + 1-23)\n",
    "\n",
    "combined_emg_all_subjects = []\n",
    "combined_labels_all_subjects = []\n",
    "\n",
    "for subject_id, subject_data in all_subjects_data.items():\n",
    "    print(f\"\\nProcessing {subject_id}:\")\n",
    "    \n",
    "    combined_emg_subject = []\n",
    "    combined_labels_subject = []\n",
    "    class_offset = 0\n",
    "    \n",
    "    for exercise in exercises:\n",
    "        if exercise not in subject_data:\n",
    "            continue\n",
    "            \n",
    "        data = subject_data[exercise]\n",
    "        emg = data['emg']\n",
    "        restimulus = data['restimulus'].flatten()\n",
    "        \n",
    "        # Get unique movements for this exercise\n",
    "        unique_movements = np.unique(restimulus)\n",
    "        movement_classes = unique_movements[unique_movements != 0]\n",
    "        \n",
    "        print(f\"  {exercise}: {len(movement_classes)} movement classes\")\n",
    "        \n",
    "        # Create relabeled stimulus\n",
    "        relabeled_stimulus = restimulus.copy()\n",
    "        \n",
    "        # Relabel movement classes (keep rest as 0)\n",
    "        for i, original_class in enumerate(movement_classes):\n",
    "            new_class = class_offset + i + 1\n",
    "            relabeled_stimulus[restimulus == original_class] = new_class\n",
    "        \n",
    "        # Update offset for next exercise\n",
    "        class_offset += len(movement_classes)\n",
    "        \n",
    "        # Add to subject's combined data\n",
    "        combined_emg_subject.append(emg)\n",
    "        combined_labels_subject.append(relabeled_stimulus)\n",
    "    \n",
    "    # Concatenate this subject's data\n",
    "    if combined_emg_subject:\n",
    "        subject_emg_combined = np.vstack(combined_emg_subject)\n",
    "        subject_labels_combined = np.concatenate(combined_labels_subject)\n",
    "        \n",
    "        combined_emg_all_subjects.append(subject_emg_combined)\n",
    "        combined_labels_all_subjects.append(subject_labels_combined)\n",
    "        \n",
    "        print(f\"  Combined shape: EMG {subject_emg_combined.shape}, Labels {subject_labels_combined.shape}\")\n",
    "\n",
    "# Final concatenation across all subjects\n",
    "print(f\"\\nFinal Combined Dataset\")\n",
    "combined_emg_array_with_rest = np.vstack(combined_emg_all_subjects)\n",
    "combined_labels_array_with_rest = np.concatenate(combined_labels_all_subjects)\n",
    "\n",
    "print(f\"Combined EMG shape (with rest): {combined_emg_array_with_rest.shape}\")\n",
    "print(f\"Combined labels shape (with rest): {combined_labels_array_with_rest.shape}\")\n",
    "\n",
    "# Remove rest class (class 0) from the dataset\n",
    "print(f\"\\nRemoving rest class\")\n",
    "mask = combined_labels_array_with_rest != 0\n",
    "combined_emg_array = combined_emg_array_with_rest[mask]\n",
    "combined_labels_array_no_rest = combined_labels_array_with_rest[mask]\n",
    "\n",
    "# Relabel classes to be consecutive (1-52 becomes 0-51)\n",
    "unique_classes_no_rest = np.unique(combined_labels_array_no_rest)\n",
    "label_mapping = {old_class: new_class for new_class, old_class in enumerate(unique_classes_no_rest)}\n",
    "\n",
    "combined_labels_array = np.array([label_mapping[label] for label in combined_labels_array_no_rest])\n",
    "\n",
    "print(f\"After removing rest class:\")\n",
    "print(f\"  EMG shape: {combined_emg_array.shape}\")\n",
    "print(f\"  Labels shape: {combined_labels_array.shape}\")\n",
    "print(f\"  Original rest samples removed: {np.sum(combined_labels_array_with_rest == 0):,}\")\n",
    "\n",
    "# Analyze final class distribution\n",
    "unique_final_classes = np.unique(combined_labels_array)\n",
    "movement_classes_final = unique_final_classes\n",
    "\n",
    "print(f\"\\nFinal class analysis (movement classes only):\")\n",
    "print(f\"Total movement classes: {len(movement_classes_final)} (classes 0-{max(movement_classes_final)})\")\n",
    "print(f\"Class range: {min(unique_final_classes)} to {max(unique_final_classes)}\")\n",
    "\n",
    "# Count samples per class (summary)\n",
    "print(f\"\\nClass distribution summary:\")\n",
    "movement_counts = []\n",
    "for class_id in movement_classes_final:\n",
    "    count = np.sum(combined_labels_array == class_id)\n",
    "    movement_counts.append(count)\n",
    "\n",
    "print(f\"  Movement classes 0-51: {min(movement_counts):,} to {max(movement_counts):,} samples each\")\n",
    "print(f\"  Total movement samples: {sum(movement_counts):,}\")\n",
    "print(f\"  Total samples: {len(combined_labels_array):,}\")\n",
    "\n",
    "print(f\"\\nCombined dataset ready in variables 'combined_emg_array' and 'combined_labels_array'\")\n",
    "print(f\"Note: Rest class has been completely removed from the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98dc43",
   "metadata": {},
   "source": [
    "## 2. Explore Dataset Structure\n",
    "\n",
    "Examine the shape, data types, and basic statistics of the combined EMG array and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb336d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"Dataset Structure Analysis\")\n",
    "print(f\"EMG Data Shape: {combined_emg_array.shape}\")\n",
    "print(f\"  - Total samples: {combined_emg_array.shape[0]:,}\")\n",
    "print(f\"  - EMG channels: {combined_emg_array.shape[1]}\")\n",
    "print(f\"Data type: {combined_emg_array.dtype}\")\n",
    "print(f\"Memory usage: {combined_emg_array.nbytes / (1024**3):.2f} GB\")\n",
    "\n",
    "print(f\"\\nLabels Shape: {combined_labels_array.shape}\")\n",
    "print(f\"Labels data type: {combined_labels_array.dtype}\")\n",
    "print(f\"Unique labels: {len(np.unique(combined_labels_array))}\")\n",
    "\n",
    "# EMG signal statistics\n",
    "print(\"\\nEmg Signal Statistics\")\n",
    "print(f\"Min value: {combined_emg_array.min():.3f}\")\n",
    "print(f\"Max value: {combined_emg_array.max():.3f}\")\n",
    "print(f\"Mean value: {combined_emg_array.mean():.3f}\")\n",
    "print(f\"Std deviation: {combined_emg_array.std():.3f}\")\n",
    "\n",
    "# Per-channel statistics\n",
    "print(\"\\nPer-Channel EMG Statistics\")\n",
    "for channel in range(combined_emg_array.shape[1]):\n",
    "    channel_data = combined_emg_array[:, channel]\n",
    "    print(f\"Channel {channel+1:2d}: Mean={channel_data.mean():8.3f}, Std={channel_data.std():8.3f}, \"\n",
    "          f\"Min={channel_data.min():8.3f}, Max={channel_data.max():8.3f}\")\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\nClass Distribution\")\n",
    "class_counts = Counter(combined_labels_array)\n",
    "for class_id in sorted(class_counts.keys()):\n",
    "    count = class_counts[class_id]\n",
    "    percentage = (count / len(combined_labels_array)) * 100\n",
    "    print(f\"Class {class_id:2d} (Movement {class_id+1:2d}): {count:7,} samples ({percentage:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c9adad",
   "metadata": {},
   "source": [
    "## 3. Visualize Class Distribution\n",
    "\n",
    "Create visualizations showing the distribution of samples across all 52 movement classes (rest class has been removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create exercise distribution visualization (MOVEMENT CLASSES ONLY)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Get class counts and set up data\n",
    "class_counts = Counter(combined_labels_array)\n",
    "classes = sorted(class_counts.keys())\n",
    "counts = [class_counts[c] for c in classes]\n",
    "\n",
    "# Exercise-wise distribution (updated ranges for 0-based indexing) in shades of grey\n",
    "exercise_colors = ['#2d2d2d', '#6d6d6d', '#a8a8a8']  # Dark grey, medium grey, light grey\n",
    "exercise_labels = ['E1 (Classes 0-11)', 'E2 (Classes 12-28)', 'E3 (Classes 29-51)']\n",
    "exercise_ranges = [(0, 11), (12, 28), (29, 51)]\n",
    "\n",
    "for i, (start, end) in enumerate(exercise_ranges):\n",
    "    ex_classes = [c for c in classes if start <= c <= end]\n",
    "    ex_counts = [class_counts[c] for c in ex_classes]\n",
    "    ax.bar(ex_classes, ex_counts, alpha=0.8, color=exercise_colors[i], \n",
    "           label=exercise_labels[i], edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_title('Sample Distribution by Class (Movement Classes Only)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Class ID (0-51)', fontsize=14)\n",
    "ax.set_ylabel('Number of Samples', fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"Class Distribution Statistics\")\n",
    "print(f\"Total movement classes: {len(classes)}\")\n",
    "print(f\"Movement samples: {sum(movement_counts):,} (100.0%)\")\n",
    "print(f\"\\nMovement class statistics:\")\n",
    "print(f\"  Mean samples per class: {np.mean(movement_counts):.1f}\")\n",
    "print(f\"  Std deviation: {np.std(movement_counts):.1f}\")\n",
    "print(f\"  Min samples: {min(movement_counts):,}\")\n",
    "print(f\"  Max samples: {max(movement_counts):,}\")\n",
    "print(f\"  Range: {max(movement_counts) - min(movement_counts):,}\")\n",
    "\n",
    "# Check class balance\n",
    "cv = np.std(movement_counts) / np.mean(movement_counts)\n",
    "print(f\"  Coefficient of variation: {cv:.3f}\")\n",
    "if cv < 0.1:\n",
    "    print(\"  → Classes are well balanced\")\n",
    "elif cv < 0.3:\n",
    "    print(\"  → Classes are moderately balanced\")\n",
    "else:\n",
    "    print(\"  → Classes are imbalanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7410ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset balance after removing rest class\n",
    "\n",
    "print(\"Dataset Balance Verification (Only Movement Classes)\")\n",
    "print(\"\")\n",
    "\n",
    "# Get class counts\n",
    "class_counts = Counter(combined_labels_array)\n",
    "movement_classes = list(class_counts.keys())\n",
    "movement_samples = [class_counts[c] for c in movement_classes]\n",
    "\n",
    "# Calculate statistics\n",
    "avg_movement_samples = np.mean(movement_samples)\n",
    "total_movement_samples = sum(movement_samples)\n",
    "\n",
    "print(f\"Total movement classes: {len(movement_classes)}\")\n",
    "print(f\"Average samples per movement class: {avg_movement_samples:.1f}\")\n",
    "print(f\"Total movement samples: {total_movement_samples:,}\")\n",
    "print(f\"\")\n",
    "print(f\"Class balance statistics:\")\n",
    "print(f\"  Min samples: {min(movement_samples):,}\")\n",
    "print(f\"  Max samples: {max(movement_samples):,}\")\n",
    "print(f\"  Standard deviation: {np.std(movement_samples):.1f}\")\n",
    "print(f\"  Coefficient of variation: {np.std(movement_samples)/avg_movement_samples:.3f}\")\n",
    "print(f\"\")\n",
    "print(f\"Rest class successfully removed\")\n",
    "print(f\"No more class imbalance issues from dominant rest class\")\n",
    "print(f\"All classes are now movement/gesture classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be32fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine how classes are organized in the data\n",
    "print(\"Data Organization Analysis\")\n",
    "print(\"\")\n",
    "\n",
    "# Check if all samples of each class are grouped together or mixed by subject\n",
    "print(\"\\n1. Checking class organization:\")\n",
    "print(\"   Are all samples of class 1 stored together, or mixed by subject?\")\n",
    "\n",
    "# Look at the first 10,000 samples to see the pattern\n",
    "sample_size = 10000\n",
    "sample_labels = combined_labels_array[:sample_size]\n",
    "print(f\"\\nFirst {sample_size} labels preview:\")\n",
    "print(f\"Labels: {sample_labels[:50]}...\")\n",
    "\n",
    "# Count transitions between classes\n",
    "transitions = 0\n",
    "for i in range(1, sample_size):\n",
    "    if sample_labels[i] != sample_labels[i-1]:\n",
    "        transitions += 1\n",
    "\n",
    "print(f\"\\nClass transitions in first {sample_size} samples: {transitions}\")\n",
    "if transitions > sample_size * 0.1:  # More than 10% transitions\n",
    "    print(\"→ MIXED: Classes are mixed/interleaved (not grouped by class)\")\n",
    "else:\n",
    "    print(\"→ GROUPED: Classes appear to be grouped together\")\n",
    "\n",
    "# Analyze the full dataset structure\n",
    "print(f\"\\n2. Full data analysis:\")\n",
    "total_transitions = 0\n",
    "for i in range(1, len(combined_labels_array)):\n",
    "    if combined_labels_array[i] != combined_labels_array[i-1]:\n",
    "        total_transitions += 1\n",
    "\n",
    "print(f\"Total class transitions in full dataset: {total_transitions:,}\")\n",
    "print(f\"Total samples: {len(combined_labels_array):,}\")\n",
    "print(f\"Transition rate: {total_transitions/len(combined_labels_array)*100:.2f}%\")\n",
    "\n",
    "if total_transitions > len(combined_labels_array) * 0.05:  # More than 5% transitions\n",
    "    print(\"→ MIXED: Data is organized by SUBJECT/TIME, not by class\")\n",
    "    print(\"   (This is the correct format for time-series EMG data)\")\n",
    "else:\n",
    "    print(\"→ GROUPED: Data is organized by CLASS\")\n",
    "    print(\"   (This would be unusual for EMG time-series data)\")\n",
    "\n",
    "# Check the pattern for a specific class\n",
    "target_class = 0\n",
    "class_indices = np.where(combined_labels_array == target_class)[0]\n",
    "consecutive_blocks = []\n",
    "block_start = class_indices[0]\n",
    "block_length = 1\n",
    "\n",
    "for i in range(1, len(class_indices)):\n",
    "    if class_indices[i] == class_indices[i-1] + 1:  # Consecutive\n",
    "        block_length += 1\n",
    "    else:  # Gap found\n",
    "        consecutive_blocks.append(block_length)\n",
    "        block_start = class_indices[i]\n",
    "        block_length = 1\n",
    "consecutive_blocks.append(block_length)  # Add the last block\n",
    "\n",
    "print(f\"\\n3. CLASS {target_class} DISTRIBUTION ANALYSIS:\")\n",
    "print(f\"Total occurrences of class {target_class}: {len(class_indices):,}\")\n",
    "print(f\"Number of separate blocks: {len(consecutive_blocks)}\")\n",
    "print(f\"Block sizes: min={min(consecutive_blocks)}, max={max(consecutive_blocks)}, avg={np.mean(consecutive_blocks):.1f}\")\n",
    "\n",
    "if len(consecutive_blocks) > 20:  # Many separate blocks\n",
    "    print(f\"→ Class {target_class} appears in {len(consecutive_blocks)} separate time segments\")\n",
    "    print(\"→ This indicates data is organized by SUBJECT/TIME (correct for EMG)\")\n",
    "else:\n",
    "    print(f\"→ Class {target_class} appears in few large blocks\")\n",
    "    print(\"→ This would indicate data is organized by CLASS (unusual for EMG)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24079cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of data organization by subject and exercise\n",
    "print(\"\\nDetailed Data Organization Analysis\")\n",
    "print(\"\")\n",
    "\n",
    "# Recreate the subject-wise organization to understand the structure\n",
    "print(\"\\n4. How the data was originally combined:\")\n",
    "print(\"   Understanding the concatenation process...\")\n",
    "\n",
    "# Let's look at how data was combined from the loading process\n",
    "print(\"\\nOriginal data combination process:\")\n",
    "print(\"1. For each subject (S1-S10):\")\n",
    "print(\"   - Load E1, E2, E3 exercises\")\n",
    "print(\"   - Concatenate all exercises for that subject\")\n",
    "print(\"   - Add subject's combined data to final array\")\n",
    "print(\"2. Final step: Concatenate all subjects vertically\")\n",
    "\n",
    "# This means the data structure is:\n",
    "# [S1_E1+E2+E3] + [S2_E1+E2+E3] + [S3_E1+E2+E3] + ... + [S10_E1+E2+E3]\n",
    "\n",
    "print(f\"\\n5. Actual Data Organization:\")\n",
    "print(f\"The data is organized as:\")\n",
    "print(f\"[Subject 1: E1+E2+E3] → [Subject 2: E1+E2+E3] → ... → [Subject 10: E1+E2+E3]\")\n",
    "\n",
    "# Let's verify this by checking the 10 blocks for class 0\n",
    "print(f\"\\n6. Verification - Class 0 Blocks:\")\n",
    "target_class = 0\n",
    "class_indices = np.where(combined_labels_array == target_class)[0]\n",
    "\n",
    "# Find block boundaries\n",
    "block_starts = [class_indices[0]]\n",
    "block_ends = []\n",
    "current_block_start = class_indices[0]\n",
    "\n",
    "for i in range(1, len(class_indices)):\n",
    "    if class_indices[i] != class_indices[i-1] + 1:  # Gap found\n",
    "        block_ends.append(class_indices[i-1])\n",
    "        block_starts.append(class_indices[i])\n",
    "        current_block_start = class_indices[i]\n",
    "block_ends.append(class_indices[-1])\n",
    "\n",
    "print(f\"Class {target_class} appears in {len(block_starts)} blocks:\")\n",
    "for i, (start, end) in enumerate(zip(block_starts, block_ends)):\n",
    "    block_size = end - start + 1\n",
    "    print(f\"  Block {i+1}: positions {start:7,} to {end:7,} (size: {block_size:5,})\")\n",
    "\n",
    "print(f\"\\n7. Conclusion:\")\n",
    "print(f\"Each class appears in exactly 10 blocks = 10 subjects\")\n",
    "print(f\"Within each subject, classes are grouped by exercise (E1→E2→E3)\")\n",
    "print(f\"Data organization: BY SUBJECT, then BY EXERCISE, then BY TIME\")\n",
    "print(f\"This is the CORRECT format for EMG time-series data\")\n",
    "\n",
    "print(f\"\\nData flow:\")\n",
    "print(f\"Subject 1: [E1 classes 0-11] → [E2 classes 12-28] → [E3 classes 29-51]\")\n",
    "print(f\"Subject 2: [E1 classes 0-11] → [E2 classes 12-28] → [E3 classes 29-51]\") \n",
    "print(f\"...\")\n",
    "print(f\"Subject 10: [E1 classes 0-11] → [E2 classes 12-28] → [E3 classes 29-51]\")\n",
    "\n",
    "print(f\"\\n8. Implications for machine learning:\")\n",
    "print(f\"Temporal structure is preserved within subjects\")\n",
    "print(f\"Each class appears across all 10 subjects\")\n",
    "print(f\"Split-first approach will properly separate subjects\")\n",
    "print(f\"No risk of data leakage between train/test splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9ba34",
   "metadata": {},
   "source": [
    "## 5. Stratified K-Fold Cross-Validation Setup\n",
    "\n",
    "Implement stratified k-fold cross-validation to ensure robust model evaluation across all 52 movement classes while maintaining proper class distribution in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Stratified K-Fold Cross-Validation Setup\")\n",
    "print(\"\")\n",
    "\n",
    "# Configuration\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "WINDOW_SIZE = 200\n",
    "OVERLAP_RATIO = 0.5\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Number of folds: {N_FOLDS}\")\n",
    "print(f\"  Window size: {WINDOW_SIZE}\")\n",
    "print(f\"  Overlap ratio: {OVERLAP_RATIO}\")\n",
    "print(f\"  Random state: {RANDOM_STATE}\")\n",
    "\n",
    "# Initialize stratified k-fold\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"\\nDataset overview:\")\n",
    "print(f\"  Total samples: {len(combined_emg_array):,}\")\n",
    "print(f\"  EMG channels: {combined_emg_array.shape[1]}\")\n",
    "print(f\"  Number of classes: {len(np.unique(combined_labels_array))}\")\n",
    "print(f\"  Classes range: {min(combined_labels_array)} to {max(combined_labels_array)}\")\n",
    "\n",
    "# Check class distribution before splitting\n",
    "class_counts = Counter(combined_labels_array)\n",
    "print(f\"\\nClass distribution before splitting:\")\n",
    "print(f\"  Min samples per class: {min(class_counts.values()):,}\")\n",
    "print(f\"  Max samples per class: {max(class_counts.values()):,}\")\n",
    "print(f\"  Average samples per class: {np.mean(list(class_counts.values())):.1f}\")\n",
    "\n",
    "# Verify that stratification will work\n",
    "min_class_count = min(class_counts.values())\n",
    "if min_class_count < N_FOLDS:\n",
    "    print(f\"\\nWARNING: Smallest class has only {min_class_count} samples\")\n",
    "    print(f\"   This is less than {N_FOLDS} folds - stratification may fail!\")\n",
    "else:\n",
    "    print(f\"\\nAll classes have sufficient samples for {N_FOLDS}-fold stratification\")\n",
    "\n",
    "print(f\"\\nExpected samples per fold: ~{len(combined_labels_array) // N_FOLDS:,}\")\n",
    "print(f\"Expected samples per class per fold: ~{min_class_count // N_FOLDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f39771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlapping_windows(X, y, window_size, overlap_ratio, label_consistency_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Create overlapping windows from time series data with label consistency checking.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray\n",
    "        Input data with shape (n_samples, n_features)\n",
    "    y : numpy.ndarray\n",
    "        Labels with shape (n_samples,)\n",
    "    window_size : int\n",
    "        Size of each window\n",
    "    overlap_ratio : float\n",
    "        Overlap between windows (0.0 to 1.0)\n",
    "    label_consistency_threshold : float\n",
    "        Minimum ratio of consistent labels required in a window\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    windows : numpy.ndarray\n",
    "        Windowed data with shape (n_windows, window_size, n_features)\n",
    "    window_labels : numpy.ndarray\n",
    "        Labels for each window\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate step size based on overlap\n",
    "    step_size = int(window_size * (1 - overlap_ratio))\n",
    "    \n",
    "    windows = []\n",
    "    window_labels = []\n",
    "    \n",
    "    # Create windows\n",
    "    for start in range(0, len(X) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        \n",
    "        # Extract window\n",
    "        window_data = X[start:end]\n",
    "        window_label_sequence = y[start:end]\n",
    "        \n",
    "        # Determine the window label using majority vote\n",
    "        unique_labels, counts = np.unique(window_label_sequence, return_counts=True)\n",
    "        majority_label = unique_labels[np.argmax(counts)]\n",
    "        \n",
    "        # Check label consistency\n",
    "        consistency = np.sum(window_label_sequence == majority_label) / len(window_label_sequence)\n",
    "        \n",
    "        # Only keep windows with sufficient label consistency\n",
    "        if consistency >= label_consistency_threshold:\n",
    "            windows.append(window_data)\n",
    "            window_labels.append(majority_label)\n",
    "    \n",
    "    return np.array(windows), np.array(window_labels)\n",
    "\n",
    "print(\"Windowing function defined\")\n",
    "print(\"  - Creates overlapping windows from time series\")\n",
    "print(\"  - Uses majority vote for window labels\")\n",
    "print(\"  - Filters out inconsistent windows (>80% consistency required)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57849b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_AUGMENT = 2  # Number of augmentations per original set\n",
    "\n",
    "def augment_emg_windows(X, noise_pct=0.05, scale_range=(0.9, 1.1), jitter_max=0.05):\n",
    "    # Calculate standard deviation per channel in the window\n",
    "    signal_std = np.std(X, axis=(0, 1), keepdims=True)\n",
    "    noise_std = signal_std * noise_pct\n",
    "    # Add Gaussian noise relative to signal std\n",
    "    X_aug = X + np.random.normal(0, noise_std, X.shape)\n",
    "    # Random scaling\n",
    "    scale = np.random.uniform(scale_range[0], scale_range[1], (X.shape[0], 1, 1))\n",
    "    X_aug = X_aug * scale\n",
    "    # Jitter\n",
    "    jitter = np.random.uniform(-jitter_max, jitter_max, X.shape)\n",
    "    X_aug = X_aug + jitter\n",
    "    return X_aug\n",
    "\n",
    "# Store all fold data\n",
    "kfold_data = []\n",
    "fold_statistics = []\n",
    "\n",
    "for fold_idx, (train_indices, test_indices) in enumerate(skf.split(combined_emg_array, combined_labels_array)):\n",
    "    print(f\"\\nProcessing Fold {fold_idx + 1}/{N_FOLDS}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_raw = combined_emg_array[train_indices]\n",
    "    y_train_raw = combined_labels_array[train_indices]\n",
    "    X_test_raw = combined_emg_array[test_indices]\n",
    "    y_test_raw = combined_labels_array[test_indices]\n",
    "    \n",
    "    print(f\"  Raw split - Train: {len(X_train_raw):,}, Test: {len(X_test_raw):,}\")\n",
    "    \n",
    "    # Create windowed data\n",
    "    print(\"  Creating windowed data\")\n",
    "    X_train_windowed, y_train_windowed = create_overlapping_windows(\n",
    "        X_train_raw, y_train_raw, WINDOW_SIZE, OVERLAP_RATIO\n",
    "    )\n",
    "    X_test_windowed, y_test_windowed = create_overlapping_windows(\n",
    "        X_test_raw, y_test_raw, WINDOW_SIZE, OVERLAP_RATIO\n",
    "    )\n",
    "    \n",
    "    # Augmentiere Trainingsdaten mehrfach und hänge sie an die Originaldaten an\n",
    "    X_augmented_list = [X_train_windowed]\n",
    "    y_augmented_list = [y_train_windowed]\n",
    "    for _ in range(N_AUGMENT):\n",
    "        X_aug = augment_emg_windows(X_train_windowed)\n",
    "        X_augmented_list.append(X_aug)\n",
    "        y_augmented_list.append(y_train_windowed)  # Labels bleiben gleich\n",
    "\n",
    "    X_train_windowed = np.concatenate(X_augmented_list, axis=0)\n",
    "    y_train_windowed = np.concatenate(y_augmented_list, axis=0)\n",
    "\n",
    "    print(f\"  Windowed data - Train: {len(X_train_windowed):,}, Test: {len(X_test_windowed):,}\")\n",
    "    \n",
    "    # Check class distribution in windowed data\n",
    "    train_classes = np.unique(y_train_windowed)\n",
    "    test_classes = np.unique(y_test_windowed)\n",
    "    \n",
    "    if len(train_classes) != 52 or len(test_classes) != 52:\n",
    "        print(f\"  Warning: Missing classes - Train: {len(train_classes)}/52, Test: {len(test_classes)}/52\")\n",
    "    else:\n",
    "        print(f\"  All 52 classes present in both train and test sets\")\n",
    "    \n",
    "    # Normalize data (fit on train, transform both)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Reshape for normalization (flatten windows)\n",
    "    X_train_flat = X_train_windowed.reshape(-1, X_train_windowed.shape[-1])\n",
    "    X_test_flat = X_test_windowed.reshape(-1, X_test_windowed.shape[-1])\n",
    "    \n",
    "    # Fit scaler on training data only\n",
    "    scaler.fit(X_train_flat)\n",
    "    \n",
    "    # Transform both sets\n",
    "    X_train_normalized = scaler.transform(X_train_flat).reshape(X_train_windowed.shape)\n",
    "    X_test_normalized = scaler.transform(X_test_flat).reshape(X_test_windowed.shape)\n",
    "    \n",
    "    # Compute class weights for this fold\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced', \n",
    "        classes=np.unique(y_train_windowed), \n",
    "        y=y_train_windowed\n",
    "    )\n",
    "    class_weight_dict = dict(zip(np.unique(y_train_windowed), class_weights))\n",
    "    \n",
    "    # Store fold data\n",
    "    fold_data = {\n",
    "        'fold_idx': fold_idx,\n",
    "        'X_train': X_train_normalized,\n",
    "        'y_train': y_train_windowed,\n",
    "        'X_test': X_test_normalized,\n",
    "        'y_test': y_test_windowed,\n",
    "        'scaler': scaler,\n",
    "        'class_weights': class_weight_dict,\n",
    "        'train_indices': train_indices,\n",
    "        'test_indices': test_indices\n",
    "    }\n",
    "    kfold_data.append(fold_data)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    train_class_counts = Counter(y_train_windowed)\n",
    "    test_class_counts = Counter(y_test_windowed)\n",
    "    \n",
    "    fold_stats = {\n",
    "        'fold': fold_idx + 1,\n",
    "        'train_samples': len(X_train_normalized),\n",
    "        'test_samples': len(X_test_normalized),\n",
    "        'train_classes': len(train_class_counts),\n",
    "        'test_classes': len(test_class_counts),\n",
    "        'train_min_class': min(train_class_counts.values()) if train_class_counts else 0,\n",
    "        'train_max_class': max(train_class_counts.values()) if train_class_counts else 0,\n",
    "        'test_min_class': min(test_class_counts.values()) if test_class_counts else 0,\n",
    "        'test_max_class': max(test_class_counts.values()) if test_class_counts else 0\n",
    "    }\n",
    "    fold_statistics.append(fold_stats)\n",
    "    \n",
    "    print(f\"  Fold {fold_idx + 1} processed successfully\")\n",
    "\n",
    "print(f\"\\nAll {N_FOLDS} Folds Created Successfully\")\n",
    "print(f\"Total folds with complete data: {len(kfold_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030dba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display fold statistics\n",
    "print(\"\\nK-Fold Statistics Summary\")\n",
    "print(\"\")\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "import pandas as pd\n",
    "df_stats = pd.DataFrame(fold_statistics)\n",
    "\n",
    "print(\"Per-fold statistics:\")\n",
    "print(df_stats.to_string(index=False))\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\nOverall K-Fold Statistics:\")\n",
    "print(f\"  Average train samples per fold: {df_stats['train_samples'].mean():.0f}\")\n",
    "print(f\"  Average test samples per fold: {df_stats['test_samples'].mean():.0f}\")\n",
    "print(f\"  Train/test ratio: {df_stats['train_samples'].mean() / df_stats['test_samples'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\nClass distribution consistency:\")\n",
    "print(f\"  All folds have all 52 classes: {all(df_stats['train_classes'] == 52) and all(df_stats['test_classes'] == 52)}\")\n",
    "print(f\"  Train set class balance (min-max per fold):\")\n",
    "for i, stats in enumerate(fold_statistics):\n",
    "    ratio = stats['train_max_class'] / stats['train_min_class'] if stats['train_min_class'] > 0 else float('inf')\n",
    "    print(f\"    Fold {i+1}: {stats['train_min_class']}-{stats['train_max_class']} samples (ratio: {ratio:.2f})\")\n",
    "\n",
    "#Sample Distribution Across K-Folds\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "folds = df_stats['fold']\n",
    "ax1.bar(folds, df_stats['train_samples'], alpha=0.7, label='Train', color='#2d2d2d')\n",
    "ax1.bar(folds, df_stats['test_samples'], alpha=0.7, label='Test', color=\"#a8a8a8\")\n",
    "ax1.set_xlabel('Fold')\n",
    "ax1.set_ylabel('Number of Samples')\n",
    "ax1.set_title('Sample Distribution Across K-Folds')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Class Balance Within Training Folds\n",
    "fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "ax2.bar(folds, df_stats['train_min_class'], alpha=0.7, label='Min class (train)', color='#2d2d2d')\n",
    "ax2.bar(folds, df_stats['train_max_class'], alpha=0.7, label='Max class (train)', color='#a8a8a8')\n",
    "ax2.set_xlabel('Fold')\n",
    "ax2.set_ylabel('Samples per Class')\n",
    "ax2.set_title('Class Balance Within Training Folds')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSTRATIFIED K-FOLD SETUP COMPLETE\")\n",
    "print(f\"Ready for cross-validation training with {N_FOLDS} folds\")\n",
    "print(f\"Data stored in 'kfold_data' list - each fold contains:\")\n",
    "print(f\"  - Preprocessed and normalized training/test data\")\n",
    "print(f\"  - Windowed EMG signals ({WINDOW_SIZE} timesteps)\")\n",
    "print(f\"  - Balanced class weights\")\n",
    "print(f\"  - Individual scalers fitted on training data only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-FOLD DATA VALIDATION - Are the folds actually different?\n",
    "print(\"\\nK-Fold Data Validation\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Detailed Fold Analysis:\")\n",
    "print(\"\")\n",
    "\n",
    "# Check if the issue is visual or actual data duplication\n",
    "print(\"1. Checking sample distribution differences:\")\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    fold_data = kfold_data[i]\n",
    "    train_classes = np.unique(fold_data['y_train'], return_counts=True)\n",
    "    test_classes = np.unique(fold_data['y_test'], return_counts=True)\n",
    "    \n",
    "    print(f\"\\nFold {i+1}:\")\n",
    "    print(f\"  Train samples: {len(fold_data['X_train']):,}\")\n",
    "    print(f\"  Test samples: {len(fold_data['X_test']):,}\")\n",
    "    print(f\"  Train classes present: {len(train_classes[0])}\")\n",
    "    print(f\"  Test classes present: {len(test_classes[0])}\")\n",
    "    \n",
    "    # Show first few class counts to check for differences\n",
    "    train_counts_dict = dict(zip(train_classes[0], train_classes[1]))\n",
    "    test_counts_dict = dict(zip(test_classes[0], test_classes[1]))\n",
    "    \n",
    "    # Sample a few classes to show variation\n",
    "    sample_classes = [0, 1, 2, 3, 4]\n",
    "    train_sample_counts = [train_counts_dict.get(c, 0) for c in sample_classes]\n",
    "    test_sample_counts = [test_counts_dict.get(c, 0) for c in sample_classes]\n",
    "    \n",
    "    print(f\"  Sample class counts (classes 0-4):\")\n",
    "    print(f\"    Train: {train_sample_counts}\")\n",
    "    print(f\"    Test:  {test_sample_counts}\")\n",
    "\n",
    "print(f\"\\n2. Checking if train/test indices overlap between folds:\")\n",
    "\n",
    "# Check if any fold has overlapping indices\n",
    "index_overlaps = []\n",
    "for i in range(N_FOLDS):\n",
    "    for j in range(i+1, N_FOLDS):\n",
    "        fold_i_train = set(kfold_data[i]['train_indices'])\n",
    "        fold_j_train = set(kfold_data[j]['train_indices'])\n",
    "        \n",
    "        overlap = len(fold_i_train.intersection(fold_j_train))\n",
    "        total_unique = len(fold_i_train.union(fold_j_train))\n",
    "        overlap_percent = (overlap / total_unique) * 100 if total_unique > 0 else 0\n",
    "        \n",
    "        index_overlaps.append((i+1, j+1, overlap, overlap_percent))\n",
    "\n",
    "# Show overlap analysis\n",
    "print(\"\\nTraining index overlaps between folds:\")\n",
    "for fold_i, fold_j, overlap, overlap_percent in index_overlaps[:5]:  # Show first 5\n",
    "    print(f\"  Fold {fold_i} vs Fold {fold_j}: {overlap:,} overlapping indices ({overlap_percent:.1f}%)\")\n",
    "\n",
    "if any(overlap > 0 for _, _, overlap, _ in index_overlaps):\n",
    "    print(\"  WARNING: Some training indices overlap between folds!\")\n",
    "else:\n",
    "    print(\"  Good: No training indices overlap between folds\")\n",
    "\n",
    "print(f\"\\n3. Statistical differences in class distributions:\")\n",
    "\n",
    "# Create a more detailed statistical comparison\n",
    "class_distribution_matrix = np.zeros((N_FOLDS, 52))\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    fold_data = kfold_data[i]\n",
    "    train_classes, train_counts = np.unique(fold_data['y_train'], return_counts=True)\n",
    "    \n",
    "    # Fill in the counts for this fold\n",
    "    for class_id, count in zip(train_classes, train_counts):\n",
    "        class_distribution_matrix[i, class_id] = count\n",
    "\n",
    "# Calculate statistics\n",
    "class_means = np.mean(class_distribution_matrix, axis=0)\n",
    "class_stds = np.std(class_distribution_matrix, axis=0)\n",
    "class_cvs = class_stds / (class_means + 1e-8)  # Coefficient of variation\n",
    "\n",
    "print(f\"Class distribution statistics across folds:\")\n",
    "print(f\"  Classes with highest variation (CV > 0.1):\")\n",
    "high_var_classes = np.where(class_cvs > 0.1)[0]\n",
    "for class_id in high_var_classes[:10]:  # Show first 10\n",
    "    print(f\"    Class {class_id:2d}: mean={class_means[class_id]:6.1f}, std={class_stds[class_id]:6.1f}, CV={class_cvs[class_id]:.3f}\")\n",
    "\n",
    "if len(high_var_classes) == 0:\n",
    "    print(\"    All classes have very similar distributions across folds (CV < 0.1)\")\n",
    "\n",
    "print(f\"\\n4. Are the bar plots misleading?\")\n",
    "\n",
    "# Check if the visual similarity is due to scale issues\n",
    "train_sample_differences = []\n",
    "test_sample_differences = []\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    train_samples = len(kfold_data[i]['X_train'])\n",
    "    test_samples = len(kfold_data[i]['X_test'])\n",
    "    train_sample_differences.append(train_samples)\n",
    "    test_sample_differences.append(test_samples)\n",
    "\n",
    "train_range = max(train_sample_differences) - min(train_sample_differences)\n",
    "test_range = max(test_sample_differences) - min(test_sample_differences)\n",
    "train_cv = np.std(train_sample_differences) / np.mean(train_sample_differences)\n",
    "test_cv = np.std(test_sample_differences) / np.mean(test_sample_differences)\n",
    "\n",
    "print(f\"\\nSample count analysis:\")\n",
    "print(f\"  Training samples per fold: {train_sample_differences}\")\n",
    "print(f\"  Test samples per fold: {test_sample_differences}\")\n",
    "print(f\"  Train sample range: {train_range:,} samples\")\n",
    "print(f\"  Test sample range: {test_range:,} samples\")\n",
    "print(f\"  Train CV: {train_cv:.4f}\")\n",
    "print(f\"  Test CV: {test_cv:.4f}\")\n",
    "\n",
    "if train_cv < 0.01 and test_cv < 0.01:\n",
    "    print(f\"\\nConclusion:\")\n",
    "    print(f\"=\"*15)\n",
    "    print(\"The k-folds ARE actually very similar in size!\")\n",
    "    print(\"   This is EXPECTED with stratified k-fold cross-validation.\")\n",
    "    print(\"   - Stratified k-fold ensures each fold has similar class proportions\")\n",
    "    print(\"   - This leads to very similar fold sizes\")\n",
    "    print(\"   - The plot is NOT misleading - the folds are genuinely similar in size\")\n",
    "    print(\"\\nWhat makes folds different:\")\n",
    "    print(\"   - Different samples (indices) are in each fold\")\n",
    "    print(\"   - Same proportion of each class, but different actual samples\")\n",
    "    print(\"   - This provides different training/validation sets for robust evaluation\")\n",
    "else:\n",
    "    print(f\"\\nConclusion:\")\n",
    "    print(f\"=\"*15)\n",
    "    print(\"The folds show more variation than expected for stratified k-fold\")\n",
    "\n",
    "print(f\"\\n5. Sample identity verification:\")\n",
    "\n",
    "# Check if the actual data samples are different\n",
    "fold_0_train = kfold_data[0]['X_train'][:5]  # First 5 samples from fold 0\n",
    "fold_1_train = kfold_data[1]['X_train'][:5]  # First 5 samples from fold 1\n",
    "\n",
    "# Check if any samples are identical\n",
    "identical_samples = 0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if np.allclose(fold_0_train[i], fold_1_train[j], rtol=1e-10):\n",
    "            identical_samples += 1\n",
    "\n",
    "print(f\"Sample comparison between Fold 1 and Fold 2:\")\n",
    "print(f\"  Identical samples found in first 5: {identical_samples}/25 comparisons\")\n",
    "\n",
    "if identical_samples == 0:\n",
    "    print(\"  Different samples in different folds\")\n",
    "else:\n",
    "    print(\"  Some identical samples found across folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED K-FOLD VISUALIZATION - Better way to show fold differences\n",
    "print(\"\\nImproved K-Fold Visualization\")\n",
    "print(\"\")\n",
    "\n",
    "# Sample distribution with better scale\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "folds = df_stats['fold']\n",
    "train_samples = df_stats['train_samples']\n",
    "test_samples = df_stats['test_samples']\n",
    "\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(folds))\n",
    "\n",
    "bars1 = ax1.bar(x - bar_width/2, train_samples, width=bar_width, alpha=0.7, label='Train', color='#2d2d2d', edgecolor='#2d2d2d')\n",
    "bars2 = ax1.bar(x + bar_width/2, test_samples, width=bar_width, alpha=0.7, label='Test', color='#a8a8a8', edgecolor='#a8a8a8')\n",
    "\n",
    "for i, (train, test) in enumerate(zip(train_samples, test_samples)):\n",
    "    ax1.text(x[i] - bar_width/2, train + max(train_samples)*0.01, f'{train:,}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    ax1.text(x[i] + bar_width/2, test + max(test_samples)*0.01, f'{test:,}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax1.set_xlabel('Fold')\n",
    "ax1.set_ylabel('Number of Samples')\n",
    "ax1.set_title('Sample Distribution')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(folds)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relative differences from mean\n",
    "fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "train_mean = np.mean(train_samples)\n",
    "test_mean = np.mean(test_samples)\n",
    "\n",
    "train_relative = [(x - train_mean) / train_mean * 100 for x in train_samples]\n",
    "test_relative = [(x - test_mean) / test_mean * 100 for x in test_samples]\n",
    "\n",
    "ax2.bar(folds, train_relative, alpha=0.7, label='Train difference from mean', color='#2d2d2d')\n",
    "ax2.bar(folds, test_relative, alpha=0.7, label='Test difference from mean', color='#a8a8a8')\n",
    "\n",
    "ax2.set_xlabel('Fold')\n",
    "ax2.set_ylabel('Percentage Difference from Mean')\n",
    "ax2.set_title('Relative Differences Between Folds')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='#888888', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Class distribution heatmap\n",
    "fig3, ax3 = plt.subplots(figsize=(8, 6))\n",
    "sample_classes = list(range(0, 52, 3))[:20]  # Every 3rd class\n",
    "class_data_sample = class_distribution_matrix[:, sample_classes]\n",
    "\n",
    "# Normalize each class row to show relative distribution across folds (percentages)\n",
    "class_data_sample_pct = class_data_sample / class_data_sample.sum(axis=0, keepdims=True) * 100\n",
    "\n",
    "im = ax3.imshow(class_data_sample_pct.T, aspect='auto', cmap='Greys', interpolation='nearest')\n",
    "ax3.set_xlabel('Fold')\n",
    "ax3.set_ylabel('Class ID')\n",
    "ax3.set_title('Class Distribution Heatmap')\n",
    "ax3.set_xticks(range(N_FOLDS))\n",
    "ax3.set_xticklabels([f'Fold {i+1}' for i in range(N_FOLDS)])\n",
    "ax3.set_yticks(range(len(sample_classes)))\n",
    "ax3.set_yticklabels(sample_classes)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
    "cbar.set_label('Percentage of Samples')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Subject distribution per fold\n",
    "fig4, ax4 = plt.subplots(figsize=(8, 6))\n",
    "subject_distribution = np.zeros((N_FOLDS, 10))  # Assuming 10 subjects\n",
    "\n",
    "for fold_idx in range(N_FOLDS):\n",
    "    train_indices = kfold_data[fold_idx]['train_indices']\n",
    "    total_samples = len(combined_labels_array)\n",
    "    samples_per_subject = total_samples // 10\n",
    "    for idx in train_indices:\n",
    "        subject = min(9, idx // samples_per_subject)\n",
    "        subject_distribution[fold_idx, subject] += 1\n",
    "\n",
    "subject_distribution_pct = subject_distribution / np.sum(subject_distribution, axis=1, keepdims=True) * 100\n",
    "\n",
    "im2 = ax4.imshow(subject_distribution_pct, aspect='auto', cmap='Greys', interpolation='nearest')\n",
    "ax4.set_xlabel('Subject')\n",
    "ax4.set_ylabel('Fold')\n",
    "ax4.set_title('Subject Data Distribution per Fold')\n",
    "ax4.set_xticks(range(10))\n",
    "ax4.set_xticklabels([f'S{i+1}' for i in range(10)])\n",
    "ax4.set_yticks(range(N_FOLDS))\n",
    "ax4.set_yticklabels([f'Fold {i+1}' for i in range(N_FOLDS)])\n",
    "\n",
    "cbar2 = plt.colorbar(im2, ax=ax4, shrink=0.8)\n",
    "cbar2.set_label('Percentage')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key statistics summary\n",
    "print(\"\\nFold Differences Summary:\")\n",
    "print(\"\")\n",
    "train_cv = np.std(train_samples) / np.mean(train_samples) * 100\n",
    "test_cv = np.std(test_samples) / np.mean(test_samples) * 100\n",
    "max_class_cv = np.max(class_cvs) * 100\n",
    "\n",
    "print(f\"Sample Count Variation:\")\n",
    "print(f\"• Train CV: {train_cv:.3f}%\")\n",
    "print(f\"• Test CV: {test_cv:.3f}%\")\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"• Max class CV: {max_class_cv:.1f}%\")\n",
    "print(f\"• Classes with CV > 10%: {len(high_var_classes)}\")\n",
    "print(f\"\\nConclusion: The folds ARE different - they contain different samples\")\n",
    "print(f\"but maintain similar proportions due to stratified sampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42617cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate how to access k-fold data\n",
    "print(\"Accessing K-Fold Data\")\n",
    "print(\"\")\n",
    "\n",
    "# Show structure of the first fold\n",
    "fold_0 = kfold_data[0]\n",
    "print(f\"Fold 0 structure:\")\n",
    "for key, value in fold_0.items():\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"  {key}: {type(value).__name__} {value.shape}\")\n",
    "    elif isinstance(value, dict):\n",
    "        print(f\"  {key}: dict with {len(value)} items\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(value).__name__}\")\n",
    "\n",
    "print(f\"\\nExample usage:\")\n",
    "print(f\"# Access fold 0 training data:\")\n",
    "print(f\"X_train = kfold_data[0]['X_train']  # Shape: {fold_0['X_train'].shape}\")\n",
    "print(f\"y_train = kfold_data[0]['y_train']  # Shape: {fold_0['y_train'].shape}\")\n",
    "print(f\"class_weights = kfold_data[0]['class_weights']  # {len(fold_0['class_weights'])} classes\")\n",
    "\n",
    "print(f\"\\nData characteristics:\")\n",
    "print(f\"  Input shape per sample: (window_size={WINDOW_SIZE}, channels={fold_0['X_train'].shape[2]})\")\n",
    "print(f\"  Output classes: {len(np.unique(fold_0['y_train']))} classes (0-51)\")\n",
    "print(f\"  Ready for CNN-LSTM model input!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6aa54",
   "metadata": {},
   "source": [
    "## Understanding WINDOW_SIZE = 200: How EMG Time Series is Split\n",
    "\n",
    "This section explains exactly how the windowing process works and how one class from one subject gets split into multiple training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb231180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMONSTRATION: How WINDOW_SIZE = 200 Works\n",
    "print(\"Windowing Demonstration\")\n",
    "print(\"\")\n",
    "\n",
    "# Let's analyze one specific class from one subject to show exactly how windowing works\n",
    "print(\"1. Original Data Structure\")\n",
    "print(\"\")\n",
    "\n",
    "# Find a specific example: Class 0 from Subject 1\n",
    "target_class = 0\n",
    "class_indices = np.where(combined_labels_array == target_class)[0]\n",
    "\n",
    "# The first block should be from Subject 1\n",
    "first_block_start = class_indices[0]\n",
    "first_block_end = None\n",
    "\n",
    "# Find where this block ends (where labels change)\n",
    "for i in range(1, len(class_indices)):\n",
    "    if class_indices[i] != class_indices[i-1] + 1:  # Gap found\n",
    "        first_block_end = class_indices[i-1]\n",
    "        break\n",
    "\n",
    "if first_block_end is None:  # Last block\n",
    "    first_block_end = class_indices[-1]\n",
    "\n",
    "block_size = first_block_end - first_block_start + 1\n",
    "\n",
    "print(f\"Example: Class {target_class} in Subject 1\")\n",
    "print(f\"  Original continuous sequence:\")\n",
    "print(f\"  - Start position: {first_block_start:,}\")\n",
    "print(f\"  - End position: {first_block_end:,}\")\n",
    "print(f\"  - Total samples: {block_size:,}\")\n",
    "print(f\"  - EMG shape for this class: ({block_size:,}, {combined_emg_array.shape[1]})\")\n",
    "\n",
    "# Extract this specific sequence\n",
    "class_emg_sequence = combined_emg_array[first_block_start:first_block_end+1]\n",
    "class_labels_sequence = combined_labels_array[first_block_start:first_block_end+1]\n",
    "\n",
    "print(f\"\\n2. Windowing Process\")\n",
    "print(\"\")\n",
    "print(f\"Settings:\")\n",
    "print(f\"  - WINDOW_SIZE = {WINDOW_SIZE} samples\")\n",
    "print(f\"  - OVERLAP_RATIO = {OVERLAP_RATIO} (50%)\")\n",
    "print(f\"  - Step size = {int(WINDOW_SIZE * (1 - OVERLAP_RATIO))} samples\")\n",
    "\n",
    "# Simulate the windowing process on this sequence\n",
    "step_size = int(WINDOW_SIZE * (1 - OVERLAP_RATIO))\n",
    "windows_from_this_class = 0\n",
    "valid_windows = 0\n",
    "\n",
    "print(f\"\\nWindowing this class sequence:\")\n",
    "for start in range(0, len(class_emg_sequence) - WINDOW_SIZE + 1, step_size):\n",
    "    end = start + WINDOW_SIZE\n",
    "    \n",
    "    # Extract window\n",
    "    window_labels = class_labels_sequence[start:end]\n",
    "    \n",
    "    # Check label consistency\n",
    "    window_label = np.bincount(window_labels).argmax()\n",
    "    label_consistency = np.mean(window_labels == window_label)\n",
    "    \n",
    "    windows_from_this_class += 1\n",
    "    if label_consistency >= 0.8:\n",
    "        valid_windows += 1\n",
    "    \n",
    "    if windows_from_this_class <= 5:  # Show first 5 windows as example\n",
    "        print(f\"  Window {windows_from_this_class}: samples {start:4d}-{end-1:4d}, \"\n",
    "              f\"consistency: {label_consistency:.3f}, \"\n",
    "              f\"valid: {'yes' if label_consistency >= 0.8 else 'no'}\")\n",
    "\n",
    "print(f\"  ...\")\n",
    "print(f\"  Total windows created: {windows_from_this_class}\")\n",
    "print(f\"  Valid windows (>80% consistency): {valid_windows}\")\n",
    "\n",
    "print(f\"\\n3. Result\")\n",
    "print(\"\")\n",
    "print(f\"One class sequence of {block_size:,} samples becomes:\")\n",
    "print(f\"  → {valid_windows} separate training examples\")\n",
    "print(f\"  → Each example has shape: ({WINDOW_SIZE}, {combined_emg_array.shape[1]})\")\n",
    "print(f\"  → All examples have the same label: {target_class}\")\n",
    "\n",
    "efficiency = (valid_windows * WINDOW_SIZE) / block_size\n",
    "print(f\"\\nData efficiency:\")\n",
    "print(f\"  - Original samples used: {block_size:,}\")\n",
    "print(f\"  - Window samples generated: {valid_windows * WINDOW_SIZE:,}\")\n",
    "print(f\"  - Efficiency ratio: {efficiency:.2f} (due to overlap)\")\n",
    "\n",
    "print(f\"\\n4. Across All Subject And Classes\")\n",
    "print(\"\")\n",
    "print(f\"This process happens for:\")\n",
    "print(f\"  - ALL {len(np.unique(combined_labels_array))} classes\")\n",
    "print(f\"  - ALL 10 subjects\") \n",
    "print(f\"  - Total original samples: {len(combined_labels_array):,}\")\n",
    "print(f\"  - Total windowed samples in k-fold: ~{sum(len(fold['X_train']) + len(fold['X_test']) for fold in kfold_data):,}\")\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"Yes, ONE class from ONE subject gets split into MULTIPLE training examples!\")\n",
    "print(f\"This allows the model to learn from different temporal segments of the same movement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eeced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVisual Demonstration of Windowing\")\n",
    "print(\"\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sequence_length = 1000  # Show first 1000 samples for visualization\n",
    "WINDOW_SIZE = 200  # Size of each window\n",
    "OVERLAP_RATIO = 0.5\n",
    "step_size = int(WINDOW_SIZE * (1 - OVERLAP_RATIO))\n",
    "\n",
    "# Create a dummy EMG sequence for visualization\n",
    "emg_sequence = np.zeros(sequence_length)\n",
    "window_starts = list(range(0, sequence_length - WINDOW_SIZE + 1, step_size))\n",
    "window_count = len(window_starts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 2))\n",
    "ax.plot(np.arange(sequence_length), emg_sequence, color='#bbbbbb', linewidth=2, label='EMG Sequence')\n",
    "\n",
    "# Plot the first 8 windows\n",
    "for i, start in enumerate(window_starts[:8]):\n",
    "    end = start + WINDOW_SIZE\n",
    "    ax.axvspan(start, end, color='#444444', alpha=0.5, label='Window' if i == 0 else None)\n",
    "    ax.text((start + end) // 2, 0.05, f'W{i+1}', ha='center', va='bottom', fontsize=9, color='#222222', fontweight='bold')\n",
    "\n",
    "# Add ellipsis for skipped windows\n",
    "if window_count > 8:\n",
    "    ax.text(sequence_length // 2, 0.15, '...', ha='center', va='bottom', fontsize=16, color='#888888')\n",
    "\n",
    "ax.set_xlim(0, sequence_length)\n",
    "ax.set_ylim(-0.1, 0.2)\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Visual Demonstration of Windowing (First 8 Windows)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCRETE EXAMPLE: Show actual EMG signal windowing\n",
    "print(\"Concrete Example of EMG Windowing\")\n",
    "print(\"\")\n",
    "\n",
    "# Get the actual EMG sequence for Class 0, Subject 1\n",
    "target_class = 0\n",
    "class_indices = np.where(combined_labels_array == target_class)[0]\n",
    "first_block_start = class_indices[0]\n",
    "\n",
    "# Find the end of the first block\n",
    "first_block_end = None\n",
    "for i in range(1, len(class_indices)):\n",
    "    if class_indices[i] != class_indices[i-1] + 1:\n",
    "        first_block_end = class_indices[i-1]\n",
    "        break\n",
    "if first_block_end is None:\n",
    "    first_block_end = class_indices[-1]\n",
    "\n",
    "# Extract actual EMG data\n",
    "actual_emg = combined_emg_array[first_block_start:first_block_start + 1000]  # First 1000 samples\n",
    "actual_labels = combined_labels_array[first_block_start:first_block_start + 1000]\n",
    "\n",
    "print(f\"Real EMG data from Class {target_class}, Subject 1:\")\n",
    "print(f\"Shape: {actual_emg.shape}\")\n",
    "print(f\"Labels: all = {target_class} yes\")\n",
    "print()\n",
    "\n",
    "# Show first few samples of one EMG channel\n",
    "channel_0_data = actual_emg[:50, 0]  # First 50 samples, channel 0\n",
    "print(\"First 50 EMG samples from Channel 0:\")\n",
    "print(\"Sample:  \" + \" \".join([f\"{i:4d}\" for i in range(0, 50, 5)]))\n",
    "print(\"Value:   \" + \" \".join([f\"{val:4.0f}\" for val in channel_0_data[::5]]))\n",
    "print()\n",
    "\n",
    "# Apply windowing to this data\n",
    "print(\"Applying windowing function:\")\n",
    "windowed_emg, windowed_labels = create_overlapping_windows(\n",
    "    actual_emg, actual_labels, WINDOW_SIZE, OVERLAP_RATIO\n",
    ")\n",
    "\n",
    "print(f\"Result:\")\n",
    "print(f\"  Original shape: {actual_emg.shape}\")\n",
    "print(f\"  Windowed shape: {windowed_emg.shape}\")\n",
    "print(f\"  Number of windows created: {len(windowed_emg)}\")\n",
    "print(f\"  Each window shape: ({WINDOW_SIZE}, {actual_emg.shape[1]})\")\n",
    "print(f\"  All window labels: {np.unique(windowed_labels)} (should all be {target_class})\")\n",
    "\n",
    "print(\"\\nExample windows created:\")\n",
    "for i in range(min(3, len(windowed_emg))):\n",
    "    window_start = i * int(WINDOW_SIZE * (1 - OVERLAP_RATIO))\n",
    "    window_end = window_start + WINDOW_SIZE\n",
    "    print(f\"  Window {i+1}: samples {window_start:3d}-{window_end-1:3d}, \"\n",
    "          f\"shape: {windowed_emg[i].shape}, label: {windowed_labels[i]}\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"One continuous EMG recording gets split into multiple training examples\")\n",
    "print(f\"Each window is a complete 200-timestep sequence\") \n",
    "print(f\"Windows overlap by 50% for better coverage\")\n",
    "print(f\"All windows from same class have same label\")\n",
    "print(f\"Model learns from different temporal segments of same movement\")\n",
    "\n",
    "print(f\"\\nThis is exactly what happens in the k-fold data!\")\n",
    "print(f\"   Each fold contains thousands of these 200-timestep windows\")\n",
    "print(f\"   from all 52 classes across all 10 subjects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962964b",
   "metadata": {},
   "source": [
    "## 6. CNN-LSTM Model Implementation and K-Fold Training\n",
    "\n",
    "Implement a robust CNN-LSTM architecture for EMG classification and train it using stratified k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "print(\"TensorFlow/Keras imports loaded successfully\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inpuut_shape = (600, 12)  # for NinaPro 4\n",
    "#input_shape = (600, 16)  # for NinaPro 5\n",
    "\n",
    "def create_cnn_lstm_model(input_shape=(600, 16), num_classes=52, dropout_rate=0.3, model_name=\"Model_Name\"):\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Conv1D(128, 15, activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        layers.Conv1D(256, 9, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        #layers.Conv1D(128, 3, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        #layers.BatchNormalization(),\n",
    "        #layers.MaxPooling1D(2),\n",
    "        #layers.Dropout(dropout_rate),\n",
    "\n",
    "        layers.Bidirectional(layers.LSTM(96, return_sequences=True, kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001))),\n",
    "        layers.Bidirectional(layers.LSTM(64, return_sequences=False, kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001))),\n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ], name=model_name)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=RMSprop(learning_rate=0.001),\n",
    "        loss=SparseCategoricalCrossentropy(),\n",
    "        metrics=[SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a test model to show architecture\n",
    "test_model = create_cnn_lstm_model(model_name=\"EMG_CNN_LSTM\")\n",
    "test_model.summary()\n",
    "plot_model(test_model, to_file='cnn_lstm_model.png', show_shapes=True, show_layer_names=True, dpi=120)\n",
    "print(f\"\\nModel created successfully\")\n",
    "print(f\"Total parameters: {test_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e155253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Save Keras summary as LaTeX verbatim block\n",
    "with io.StringIO() as buf:\n",
    "    test_model.summary(print_fn=lambda x: buf.write(x + '\\n'))\n",
    "    summary_str = buf.getvalue()\n",
    "\n",
    "with open('cnn_lstm_model_summary.tex', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\\\begin{verbatim}\\n')\n",
    "    f.write(summary_str)\n",
    "    f.write('\\\\end{verbatim}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acedf544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback for enhanced monitoring and clean output\n",
    "\n",
    "# Global list to track best validation accuracy progression\n",
    "global_best_progression = []\n",
    "\n",
    "class CleanTrainingCallback(callbacks.Callback):\n",
    "    \"\"\"Custom callback for clean, organized training output\"\"\"\n",
    "    \n",
    "    def __init__(self, fold_num):\n",
    "        super().__init__()\n",
    "        self.fold_num = fold_num\n",
    "        self.epoch_start_time = 0\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(f\"\\nFold {self.fold_num} Training Started\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"{'Epoch':<6} {'Train Loss':<12} {'Train Acc':<12} {'Val Loss':<12} {'Val Acc':<12} {'Time':<8} {'Status'}\")\n",
    "        print(\"-\" * 72)\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        \n",
    "        # Get metrics\n",
    "        train_loss = logs.get('loss', 0)\n",
    "        train_acc = logs.get('sparse_categorical_accuracy', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        val_acc = logs.get('val_sparse_categorical_accuracy', 0)\n",
    "       \n",
    "        # Access global best accuracy variable\n",
    "        global best_global_val_acc, global_best_progression\n",
    "        \n",
    "        status = \"\"\n",
    "        # Check if this epoch improved the global best accuracy\n",
    "        if val_acc > best_global_val_acc:\n",
    "            best_global_val_acc = val_acc  # Update the global best!\n",
    "            status = \"New best accuracy\"\n",
    "            self.model.save('best_CNN_Model.keras')\n",
    "            \n",
    "        # Track global best progression (fold, epoch, current_val_acc, global_best_acc)\n",
    "        global_best_progression.append({\n",
    "            'fold': self.fold_num,\n",
    "            'epoch': epoch + 1,\n",
    "            'val_acc': val_acc,\n",
    "            'global_best': best_global_val_acc\n",
    "        })\n",
    "        \n",
    "        print(f\"{epoch+1:<6} {train_loss:<12.4f} {train_acc:<12.4f} {val_loss:<12.4f} {val_acc:<12.4f} {epoch_time:<8.1f}s {status}\")\n",
    "\n",
    "print(\"Callbacks and monitoring system loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1bb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 96\n",
    "PATIENCE = 10\n",
    "LR_PATIENCE = 5  # Patience for learning rate reduction\n",
    "VALIDATION_SPLIT = 0.15  # Use 15% of training data for validation\n",
    "\n",
    "print(\"Training configuration\")\n",
    "print(\"\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Early stopping patience: {PATIENCE}\")\n",
    "print(f\"LR reduction patience: {LR_PATIENCE}\")\n",
    "print(f\"Validation split: {VALIDATION_SPLIT}\")\n",
    "print(f\"K-folds: {N_FOLDS}\")\n",
    "\n",
    "def create_callbacks(fold_num):\n",
    "    \"\"\"Create callbacks for training with enhanced early stopping and model saving\"\"\"\n",
    "    \n",
    "    print(f\"\\nCallback configuration for fold {fold_num}\")\n",
    "    print(f\"   Early Stopping: Patience = {PATIENCE} epochs\")\n",
    "    print(f\"   Learning Rate Reduction: Factor=0.5, patience={LR_PATIENCE} epochs\")\n",
    "    print(f\"   Global Best Model: Will be saved automatically when global best is found\")\n",
    "    print()\n",
    "    \n",
    "    # Create fresh callback instances for each fold to avoid state carryover\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_sparse_categorical_accuracy',\n",
    "        patience=PATIENCE,  # Use global PATIENCE variable\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,  # Show early stopping messages\n",
    "        mode='max',  # 'max' for accuracy (we want the highest accuracy)\n",
    "        min_delta=0.0001  # Minimum improvement to count as progress\n",
    "    )\n",
    "    \n",
    "    lr_reducer = callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_sparse_categorical_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=LR_PATIENCE,  # Use global LR_PATIENCE variable\n",
    "        min_lr=1e-7,\n",
    "        verbose=1,  # Show LR reduction messages\n",
    "        mode='max',  # 'max' for accuracy\n",
    "        min_delta=0.0001\n",
    "    )\n",
    "    \n",
    "    training_callback = CleanTrainingCallback(fold_num=fold_num)\n",
    "    \n",
    "    callbacks_list = [\n",
    "        training_callback,\n",
    "        early_stopping,\n",
    "        lr_reducer\n",
    "    ]\n",
    "    \n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15783667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Storage for results\n",
    "kfold_results = {\n",
    "    'fold_num': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "    'test_acc': [],\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'test_loss': [],\n",
    "    'training_time': [],\n",
    "    'epochs_trained': []\n",
    "}\n",
    "\n",
    "# Storage for models and histories\n",
    "trained_models = []\n",
    "training_histories = []\n",
    "\n",
    "# Initialize global best progression tracking\n",
    "global_best_progression = []\n",
    "\n",
    "# Global best model tracking\n",
    "best_global_val_acc = 0.0\n",
    "best_global_model = None\n",
    "best_global_fold = 0\n",
    "\n",
    "# Start k-fold training\n",
    "start_time_total = time.time()\n",
    "\n",
    "for fold_num in range(N_FOLDS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training fold {fold_num + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Reset patience values for each fold BEFORE creating callbacks\n",
    "    PATIENCE = 10      # Early stopping patience\n",
    "    LR_PATIENCE = 5    # Learning rate reduction patience\n",
    "    \n",
    "    # Ensure completely fresh state for each fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Get pre-prepared data for this fold from kfold_data\n",
    "    fold_data = kfold_data[fold_num]\n",
    "    X_train_fold = fold_data['X_train']\n",
    "    y_train_fold = fold_data['y_train']\n",
    "    X_test_fold = fold_data['X_test']\n",
    "    y_test_fold = fold_data['y_test']\n",
    "    \n",
    "    print(f\"Fold {fold_num + 1} data:\")\n",
    "    print(f\"  Training samples: {len(X_train_fold):,}\")\n",
    "    print(f\"  Test samples: {len(X_test_fold):,}\")\n",
    "    print(f\"  Input shape: {X_train_fold.shape}\")\n",
    "    print(f\"  Output classes: {len(np.unique(y_train_fold))}\")\n",
    "    \n",
    "    # Create fresh model for this fold\n",
    "    model = create_cnn_lstm_model()\n",
    "    \n",
    "    # Create callbacks for this fold (AFTER resetting patience values)\n",
    "    fold_callbacks = create_callbacks(fold_num + 1)\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nStarting training for fold {fold_num + 1}...\")\n",
    "    start_time_fold = time.time()\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        callbacks=fold_callbacks,\n",
    "        verbose=0  # Reduced verbosity - our custom callback handles output\n",
    "    )\n",
    "    \n",
    "    training_time_fold = time.time() - start_time_fold\n",
    "    epochs_trained = len(history.history['loss'])\n",
    "    \n",
    "    # Get best validation accuracy for this fold\n",
    "    best_fold_val_acc = max(history.history['val_sparse_categorical_accuracy'])\n",
    "    \n",
    "    # Find the epoch with the best validation accuracy\n",
    "    best_epoch_idx = history.history['val_sparse_categorical_accuracy'].index(best_fold_val_acc)\n",
    "    \n",
    "    # Note: Global best model tracking and saving is handled automatically by CleanTrainingCallback\n",
    "    \n",
    "    # Evaluate on test set (model is already restored to best weights by EarlyStopping)\n",
    "    test_loss, test_acc = model.evaluate(X_test_fold, y_test_fold, verbose=0)\n",
    "    \n",
    "    # Get metrics from the BEST epoch (not the last epoch)\n",
    "    best_train_loss = history.history['loss'][best_epoch_idx]\n",
    "    best_train_acc = history.history['sparse_categorical_accuracy'][best_epoch_idx]\n",
    "    best_val_loss = history.history['val_loss'][best_epoch_idx]\n",
    "    best_val_acc = best_fold_val_acc  # It's already saved as the best validation accuracy\n",
    "    \n",
    "    # Store results (using BEST epoch metrics, not last epoch)\n",
    "    kfold_results['fold_num'].append(fold_num + 1)\n",
    "    kfold_results['train_acc'].append(best_train_acc)\n",
    "    kfold_results['val_acc'].append(best_val_acc)\n",
    "    kfold_results['test_acc'].append(test_acc)\n",
    "    kfold_results['train_loss'].append(best_train_loss)\n",
    "    kfold_results['val_loss'].append(best_val_loss)\n",
    "    kfold_results['test_loss'].append(test_loss)\n",
    "    kfold_results['training_time'].append(training_time_fold)\n",
    "    kfold_results['epochs_trained'].append(epochs_trained)\n",
    "    \n",
    "    # Store model and history\n",
    "    trained_models.append(model)\n",
    "    training_histories.append(history)\n",
    "    \n",
    "    # Explicit cleanup to ensure fresh state for next fold\n",
    "    del model, history, fold_callbacks  # Delete references\n",
    "    tf.keras.backend.clear_session()    # Clear TensorFlow session\n",
    "    \n",
    "    # Force garbage collection\n",
    "    import gc\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eae211",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kfold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze K-Fold Results\n",
    "print(\"K-Fold Results Analysis\")\n",
    "print(\"\")\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "results_df = pd.DataFrame(kfold_results)\n",
    "print(\"Individual fold results:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Calculate statistics\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(\"\")\n",
    "\n",
    "metrics = ['train_acc', 'val_acc', 'test_acc']\n",
    "for metric in metrics:\n",
    "    values = results_df[metric]\n",
    "    mean_val = values.mean()\n",
    "    std_val = values.std()\n",
    "    print(f\"{metric.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Mean ± Std: {mean_val:.4f} ± {std_val:.4f}\")\n",
    "    print(f\"  Range: {values.min():.4f} - {values.max():.4f}\")\n",
    "    print()\n",
    "\n",
    "# Performance analysis\n",
    "test_accuracies = results_df['test_acc']\n",
    "print(f\"Final Model Performance:\")\n",
    "print(f\"\")\n",
    "print(f\"Test Accuracy: {test_accuracies.mean():.4f} ± {test_accuracies.std():.4f}\")\n",
    "print(f\"Best fold: {test_accuracies.max():.4f} (Fold {test_accuracies.idxmax() + 1})\")\n",
    "print(f\"Worst fold: {test_accuracies.min():.4f} (Fold {test_accuracies.idxmin() + 1})\")\n",
    "print(f\"95% Confidence Interval: [{test_accuracies.mean() - 1.96*test_accuracies.std():.4f}, {test_accuracies.mean() + 1.96*test_accuracies.std():.4f}]\")\n",
    "\n",
    "# Compare with random baseline\n",
    "random_accuracy = 1/52  # Random chance for 52 classes\n",
    "improvement = (test_accuracies.mean() - random_accuracy) / random_accuracy * 100\n",
    "print(f\"\\nComparison with random baseline:\")\n",
    "print(f\"Random accuracy: {random_accuracy:.4f} ({random_accuracy*100:.2f}%)\")\n",
    "print(f\"Improvement: {improvement:.1f}x better than random\")\n",
    "\n",
    "# Training efficiency\n",
    "print(f\"\\nTraining Efficiency:\")\n",
    "print(\"\")\n",
    "avg_training_time = results_df['training_time'].mean()\n",
    "avg_epochs = results_df['epochs_trained'].mean()\n",
    "print(f\"Average training time per fold: {avg_training_time/60:.1f} minutes\")\n",
    "print(f\"Average epochs per fold: {avg_epochs:.1f}\")\n",
    "print(f\"Total training time: {results_df['training_time'].sum()/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ebb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Best Saved Model for Analysis\n",
    "print(\"Loading Best Saved Model for Analysis\")\n",
    "print(\"\")\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Find all saved model files\n",
    "model_files = glob.glob(\"best_CNN_Model.keras\")\n",
    "\n",
    "if model_files:\n",
    "    # Sort by modification time to get the most recent\n",
    "    model_files.sort(key=os.path.getmtime, reverse=True)\n",
    "    \n",
    "    print(f\"Found {len(model_files)} saved model files:\")\n",
    "    for i, file in enumerate(model_files[:5]):  # Show first 5\n",
    "        mod_time = time.ctime(os.path.getmtime(file))\n",
    "        file_size = os.path.getsize(file) / 1024 / 1024  # Size in MB\n",
    "        print(f\"  {i+1}. {file} ({file_size:.1f} MB, {mod_time})\")\n",
    "    \n",
    "    # Load the most recent model (or choose a specific one)\n",
    "    best_model_path = model_files[0]\n",
    "    print(f\"\\nLoading best model: {best_model_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load the model for analysis (independent of training variables)\n",
    "        analysis_model = tf.keras.models.load_model(best_model_path)\n",
    "        print(f\"Model loaded successfully!\")\n",
    "        print(f\"   Model input shape: {analysis_model.input_shape}\")\n",
    "        print(f\"   Model output shape: {analysis_model.output_shape}\")\n",
    "        print(f\"   Total parameters: {analysis_model.count_params():,}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"   Will use the last trained model from memory instead\")\n",
    "        if 'trained_models' in locals() and trained_models:\n",
    "            analysis_model = trained_models[-1]  # Use last trained model\n",
    "        else:\n",
    "            print(\"   No trained models available. Please run training first.\")\n",
    "            analysis_model = None\n",
    "            \n",
    "else:\n",
    "    print(\"No saved model files found!\")\n",
    "    print(\"   Looking for files matching pattern: best_cnn_lstm_fold_*.keras\")\n",
    "    print(\"   Please run the training first or check the file path.\")\n",
    "    \n",
    "    # Try to use models from memory if available\n",
    "    if 'trained_models' in locals() and trained_models:\n",
    "        analysis_model = trained_models[-1]\n",
    "        print(\"   Using last trained model from memory instead\")\n",
    "    else:\n",
    "        analysis_model = None\n",
    "        print(\"   No models available for analysis\")\n",
    "\n",
    "print(\"\")\n",
    "if analysis_model is not None:\n",
    "    print(\"Model loaded and available as 'analysis_model'\")\n",
    "else:\n",
    "    print(\"Please run training first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVisualising K-Fold Results\")\n",
    "print(\"\")\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.25\n",
    "\n",
    "# 1. Accuracy comparison across folds\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "ax1.bar(x_pos - width, results_df['train_acc'], width, label='Train', alpha=0.8, color='#2d2d2d')\n",
    "ax1.bar(x_pos, results_df['val_acc'], width, label='Validation', alpha=0.8, color='#6d6d6d')\n",
    "ax1.bar(x_pos + width, results_df['test_acc'], width, label='Test', alpha=0.8, color='#a8a8a8')\n",
    "ax1.set_xlabel('Fold')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Accuracy Across Folds')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels([f'Fold {i+1}' for i in range(N_FOLDS)])\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#2d2d2d', edgecolor='black', label='Train'),\n",
    "    Patch(facecolor='#6d6d6d', edgecolor='black', label='Validation'),\n",
    "    Patch(facecolor='#a8a8a8', edgecolor='black', label='Test')\n",
    "]\n",
    "ax1.legend(handles=legend_elements, loc='best', title='Grey Tone Legend')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Loss comparison across folds\n",
    "fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "ax2.bar(x_pos - width, results_df['train_loss'], width, label='Train', alpha=0.8, color='#2d2d2d')\n",
    "ax2.bar(x_pos, results_df['val_loss'], width, label='Validation', alpha=0.8, color='#6d6d6d')\n",
    "ax2.bar(x_pos + width, results_df['test_loss'], width, label='Test', alpha=0.8, color='#a8a8a8')\n",
    "ax2.set_xlabel('Fold')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Loss Across Folds')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels([f'Fold {i+1}' for i in range(N_FOLDS)])\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Training time and epochs\n",
    "fig3, ax3 = plt.subplots(figsize=(8, 6))\n",
    "ax3_twin = ax3.twinx()\n",
    "bars1 = ax3.bar(x_pos, results_df['training_time']/60, alpha=0.8, color='#6d6d6d', label='Training Time')\n",
    "ax3.set_xlabel('Fold')\n",
    "ax3.set_ylabel('Training Time / minutes', color='#6d6d6d')\n",
    "ax3.tick_params(axis='y', labelcolor='#6d6d6d')\n",
    "bars2 = ax3_twin.bar(x_pos, results_df['epochs_trained'], alpha=0.6, color='#a8a8a8', width=0.6, label='Epochs')\n",
    "ax3_twin.set_ylabel('Epochs Trained', color='#a8a8a8')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='#a8a8a8')\n",
    "ax3.set_title('Training Efficiency')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels([f'Fold {i+1}' for i in range(N_FOLDS)])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Test accuracy distribution\n",
    "fig4, ax4 = plt.subplots(figsize=(8, 6))\n",
    "ax4.hist(results_df['test_acc'], bins=10, alpha=0.7, color='#6d6d6d', edgecolor='black')\n",
    "ax4.axvline(results_df['test_acc'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {results_df[\"test_acc\"].mean():.4f}')\n",
    "ax4.set_xlabel('Test Accuracy')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Test Accuracy Distribution')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Accuracy vs Training Time\n",
    "fig5, ax5 = plt.subplots(figsize=(8, 6))\n",
    "ax5.scatter(results_df['training_time']/60, results_df['test_acc'], s=100, alpha=0.7, color='#6d6d6d')\n",
    "for i, txt in enumerate(results_df['fold_num']):\n",
    "    ax5.annotate(f'F{txt}', (results_df['training_time'].iloc[i]/60, results_df['test_acc'].iloc[i]), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "ax5.set_xlabel('Training Time (minutes)')\n",
    "ax5.set_ylabel('Test Accuracy')\n",
    "ax5.set_title('Accuracy vs Training Time')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Performance summary table\n",
    "fig6, ax6 = plt.subplots(figsize=(8, 4))\n",
    "ax6.axis('tight')\n",
    "ax6.axis('off')\n",
    "summary_data = [\n",
    "    ['Metric', 'Mean ± Std', 'Min', 'Max'],\n",
    "    ['Test Accuracy', f'{test_accuracies.mean():.4f} ± {test_accuracies.std():.4f}', \n",
    "     f'{test_accuracies.min():.4f}', f'{test_accuracies.max():.4f}'],\n",
    "    ['Val Accuracy', f'{results_df[\"val_acc\"].mean():.4f} ± {results_df[\"val_acc\"].std():.4f}', \n",
    "     f'{results_df[\"val_acc\"].min():.4f}', f'{results_df[\"val_acc\"].max():.4f}'],\n",
    "    ['Training Time (min)', f'{results_df[\"training_time\"].mean()/60:.1f} ± {results_df[\"training_time\"].std()/60:.1f}', \n",
    "     f'{results_df[\"training_time\"].min()/60:.1f}', f'{results_df[\"training_time\"].max()/60:.1f}'],\n",
    "    ['Epochs Trained', f'{results_df[\"epochs_trained\"].mean():.1f} ± {results_df[\"epochs_trained\"].std():.1f}', \n",
    "     f'{results_df[\"epochs_trained\"].min()}', f'{results_df[\"epochs_trained\"].max()}']\n",
    "]\n",
    "table = ax6.table(cellText=summary_data, cellLoc='center', loc='center', \n",
    "                 colWidths=[0.3, 0.3, 0.2, 0.2])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.5)\n",
    "for i in range(len(summary_data[0])):\n",
    "    table[(0, i)].set_facecolor('#2d2d2d')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "ax6.set_title('Performance Summary', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training Histories (Learning Curves)\n",
    "print(\"\\nTraining Histories Visualization\")\n",
    "print(\"\")\n",
    "\n",
    "# Plot learning curves for all folds\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('CNN-LSTM Training History - Learning Curves', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Colors for different folds\n",
    "colors = ['#2d2d2d', '#2d2d2d', '#2d2d2d', '#2d2d2d', '#2d2d2d'] # rudimary solution\n",
    "\n",
    "# Plot individual fold histories\n",
    "for i in range(min(N_FOLDS, 5)):  # Show up to 5 folds\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    \n",
    "    if i < len(training_histories):\n",
    "        history = training_histories[i]\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax = axes[row, col]\n",
    "        epochs = range(1, len(history.history['sparse_categorical_accuracy']) + 1)\n",
    "        \n",
    "        ax.plot(epochs, history.history['sparse_categorical_accuracy'], \n",
    "               'o-', color=colors[i], alpha=0.8, label='Train Accuracy')\n",
    "        ax.plot(epochs, history.history['val_sparse_categorical_accuracy'], \n",
    "               's-', color=colors[i], alpha=0.6, label='Val Accuracy')\n",
    "        \n",
    "        ax.set_title(f'Fold {i+1} - Learning Curves')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add final accuracies as text\n",
    "        final_train_acc = history.history['sparse_categorical_accuracy'][-1]\n",
    "        final_val_acc = history.history['val_sparse_categorical_accuracy'][-1]\n",
    "        ax.text(0.05, 0.95, f'Final Train: {final_train_acc:.3f}\\nFinal Val: {final_val_acc:.3f}', \n",
    "               transform=ax.transAxes, verticalalignment='top', \n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# If there is fewer than 6 folds, hide extra subplots\n",
    "for i in range(N_FOLDS, 6):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    if row < 2 and col < 3:\n",
    "        axes[row, col].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Aggregate learning curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Collect all training histories\n",
    "all_train_acc = []\n",
    "all_val_acc = []\n",
    "all_train_loss = []\n",
    "all_val_loss = []\n",
    "\n",
    "max_epochs = max(len(hist.history['sparse_categorical_accuracy']) for hist in training_histories)\n",
    "\n",
    "for history in training_histories:\n",
    "    all_train_acc.append(history.history['sparse_categorical_accuracy'])\n",
    "    all_val_acc.append(history.history['val_sparse_categorical_accuracy'])\n",
    "    all_train_loss.append(history.history['loss'])\n",
    "    all_val_loss.append(history.history['val_loss'])\n",
    "\n",
    "# Pad sequences to same length and compute mean/std\n",
    "def pad_and_compute_stats(sequences):\n",
    "    # Pad sequences to max length\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_epochs:\n",
    "            # Pad with last value\n",
    "            padded_seq = seq + [seq[-1]] * (max_epochs - len(seq))\n",
    "        else:\n",
    "            padded_seq = seq\n",
    "        padded.append(padded_seq)\n",
    "    \n",
    "    padded = np.array(padded)\n",
    "    mean_seq = np.mean(padded, axis=0)\n",
    "    std_seq = np.std(padded, axis=0)\n",
    "    return mean_seq, std_seq\n",
    "\n",
    "# Compute statistics\n",
    "train_acc_mean, train_acc_std = pad_and_compute_stats(all_train_acc)\n",
    "val_acc_mean, val_acc_std = pad_and_compute_stats(all_val_acc)\n",
    "train_loss_mean, train_loss_std = pad_and_compute_stats(all_train_loss)\n",
    "val_loss_mean, val_loss_std = pad_and_compute_stats(all_val_loss)\n",
    "\n",
    "epochs = range(1, max_epochs + 1)\n",
    "\n",
    "# Plot mean accuracy with confidence intervals\n",
    "fig_acc, ax_acc = plt.subplots(figsize=(8, 6))\n",
    "ax_acc.plot(epochs, train_acc_mean, 'o-', color='#2d2d2d', alpha=0.8, label='Train Accuracy')\n",
    "ax_acc.fill_between(epochs, train_acc_mean - train_acc_std, train_acc_mean + train_acc_std, alpha=0.2, color='#2d2d2d')\n",
    "ax_acc.plot(epochs, val_acc_mean, 's-', color='#a8a8a8', alpha=0.8, label='Validation Accuracy')\n",
    "ax_acc.fill_between(epochs, val_acc_mean - val_acc_std, val_acc_mean + val_acc_std, alpha=0.2, color='#a8a8a8')\n",
    "ax_acc.set_title('Average Learning Curves - Accuracy')\n",
    "ax_acc.set_xlabel('Epoch')\n",
    "ax_acc.set_ylabel('Accuracy')\n",
    "ax_acc.legend(loc='lower right')\n",
    "ax_acc.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot mean loss with confidence intervals\n",
    "fig_loss, ax_loss = plt.subplots(figsize=(8, 6))\n",
    "ax_loss.plot(epochs, train_loss_mean, 'o-', color='#2d2d2d', alpha=0.8, label='Train Loss')\n",
    "ax_loss.fill_between(epochs, train_loss_mean - train_loss_std, train_loss_mean + train_loss_std, alpha=0.2, color='#2d2d2d')\n",
    "ax_loss.plot(epochs, val_loss_mean, 's-', color='#a8a8a8', alpha=0.8, label='Validation Loss')\n",
    "ax_loss.fill_between(epochs, val_loss_mean - val_loss_std, val_loss_mean + val_loss_std, alpha=0.2, color='#a8a8a8')\n",
    "ax_loss.set_title('Average Learning Curves - Loss')\n",
    "ax_loss.set_xlabel('Epoch')\n",
    "ax_loss.set_ylabel('Loss')\n",
    "ax_loss.legend(loc='upper right')\n",
    "ax_loss.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history visualization complete!\")\n",
    "print(f\"   - Average convergence at epoch {np.argmax(val_acc_mean)+1}\")\n",
    "print(f\"   - Best validation accuracy: {np.max(val_acc_mean):.4f}\")\n",
    "print(f\"   - Final training stability: {'Good' if train_acc_std[-1] < 0.05 else 'Variable'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Best Validation Accuracy Progression\n",
    "print(\"\\nGlobal Best Validation Accuracy Progression\")\n",
    "print(\"\")\n",
    "\n",
    "if global_best_progression:\n",
    "    # Convert progression data to arrays for plotting\n",
    "    progression_df = pd.DataFrame(global_best_progression)\n",
    "    progression_df['global_epoch'] = range(1, len(progression_df) + 1)\n",
    "\n",
    "    # Current validation accuracy vs global best progression\n",
    "    fig1, ax1 = plt.subplots(figsize=(15, 6))\n",
    "    ax1.plot(progression_df['global_epoch'], progression_df['val_acc'],\n",
    "             'o-', color='lightblue', alpha=0.6, markersize=3, label='Current Val Accuracy')\n",
    "    ax1.plot(progression_df['global_epoch'], progression_df['global_best'],\n",
    "             'o-', color='darkred', linewidth=2, markersize=4, label='Global Best (Cumulative)')\n",
    "\n",
    "    # Highlight improvements\n",
    "    improvements = progression_df[progression_df['val_acc'] == progression_df['global_best']]\n",
    "    if not improvements.empty:\n",
    "        ax1.scatter(improvements['global_epoch'], improvements['global_best'],\n",
    "                    color='red', s=50, alpha=0.8, zorder=5, label='New Global Best')\n",
    "\n",
    "    # Add fold boundaries\n",
    "    fold_boundaries = []\n",
    "    current_fold = progression_df['fold'].iloc[0]\n",
    "    for i, fold in enumerate(progression_df['fold']):\n",
    "        if fold != current_fold:\n",
    "            fold_boundaries.append(i)\n",
    "            current_fold = fold\n",
    "    for boundary in fold_boundaries:\n",
    "        ax1.axvline(x=boundary, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "    ax1.set_xlabel('Global Epoch (Across All Folds)')\n",
    "    ax1.set_ylabel('Validation Accuracy')\n",
    "    ax1.set_title('Validation Accuracy Progression')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Global best accuracy by fold\n",
    "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "    fold_maxes = progression_df.groupby('fold')['global_best'].max()\n",
    "    fold_numbers = fold_maxes.index\n",
    "\n",
    "    bars = ax2.bar(fold_numbers, fold_maxes, color='steelblue', alpha=0.7, edgecolor='navy')\n",
    "    for bar, val in zip(bars, fold_maxes):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                 f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    final_best = progression_df['global_best'].iloc[-1]\n",
    "    ax2.axhline(y=final_best, color='red', linestyle='-', linewidth=2,\n",
    "                label=f'Final Global Best: {final_best:.4f}')\n",
    "\n",
    "    ax2.set_xlabel('Fold Number')\n",
    "    ax2.set_ylabel('Global Best Validation Accuracy')\n",
    "    ax2.set_title('Global Best Accuracy Reached by Each Fold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    ax2.set_xticks(fold_numbers)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary statistics\n",
    "    total_improvements = len(improvements)\n",
    "    total_epochs = len(progression_df)\n",
    "    improvement_rate = (total_improvements / total_epochs) * 100\n",
    "\n",
    "    print(f\"\\nGlobal Best Summary:\")\n",
    "    print(\"\")\n",
    "    print(f\"Total epochs trained: {total_epochs}\")\n",
    "    print(f\"Global best improvements: {total_improvements}\")\n",
    "    print(f\"Improvement rate: {improvement_rate:.1f}%\")\n",
    "    print(f\"Final global best accuracy: {final_best:.4f}\")\n",
    "\n",
    "    # Which fold contributed most improvements\n",
    "    improvement_by_fold = improvements['fold'].value_counts().sort_index()\n",
    "    print(f\"\\nImprovements by fold:\")\n",
    "    for fold, count in improvement_by_fold.items():\n",
    "        print(f\"   Fold {fold}: {count} improvements\")\n",
    "\n",
    "    if not improvement_by_fold.empty:\n",
    "        best_contributing_fold = improvement_by_fold.idxmax()\n",
    "        print(f\"\\nFold {best_contributing_fold} contributed the most improvements ({improvement_by_fold.max()} times)\")\n",
    "\n",
    "else:\n",
    "    print(\"No global best progression data available. Please run the training first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f73ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Confusion Matrix for All 52 Classes\n",
    "print(\"\\nConfusion Matrix Analysis for All 52 Classes\")\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Use the best model to make predictions on all test data\n",
    "print(\"Generating predictions using the best model...\")\n",
    "\n",
    "# Combine all test data from all folds to get comprehensive results\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    fold_data = kfold_data[i]\n",
    "    X_test_fold = fold_data['X_test']\n",
    "    y_test_fold = fold_data['y_test']\n",
    "    \n",
    "    # Make predictions using the best saved model\n",
    "    y_pred_fold = analysis_model.predict(X_test_fold, verbose=0)\n",
    "    y_pred_fold_classes = np.argmax(y_pred_fold, axis=1)\n",
    "    \n",
    "    all_y_true.extend(y_test_fold)\n",
    "    all_y_pred.extend(y_pred_fold_classes)\n",
    "\n",
    "all_y_true = np.array(all_y_true)\n",
    "all_y_pred = np.array(all_y_pred)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(all_y_true, all_y_pred)\n",
    "print(f\"Confusion matrix shape: {cm.shape}\")\n",
    "print(f\"Total test samples: {len(all_y_true):,}\")\n",
    "\n",
    "tick_marks = np.arange(0, 52, 5)\n",
    "\n",
    "# 1. Full confusion matrix (heatmap)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.title('Full Confusion Matrix (52x52)', fontweight='bold')\n",
    "im1 = plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.colorbar(im1, shrink=0.8, label='Number of Samples')\n",
    "plt.xticks(tick_marks)\n",
    "plt.yticks(tick_marks)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Normalized confusion matrix (percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.title('Normalized Confusion Matrix (Recall per Class)', fontweight='bold')\n",
    "im2 = plt.imshow(cm_normalized, interpolation='nearest', cmap='Reds', vmin=0, vmax=1)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.colorbar(im2, shrink=0.8, label='Recall (True Positive Rate)')\n",
    "plt.xticks(tick_marks)\n",
    "plt.yticks(tick_marks)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Per-class accuracy (diagonal elements of normalized confusion matrix)\n",
    "class_accuracies = np.diag(cm_normalized)\n",
    "classes = np.arange(52)\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars = plt.bar(classes, class_accuracies, color='steelblue', alpha=0.7, edgecolor='navy', linewidth=0.5)\n",
    "plt.title('Per-Class Recall (Accuracy)', fontweight='bold')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "best_class = np.argmax(class_accuracies)\n",
    "worst_class = np.argmin(class_accuracies)\n",
    "bars[best_class].set_color('green')\n",
    "bars[worst_class].set_color('red')\n",
    "avg_accuracy = np.mean(class_accuracies)\n",
    "plt.axhline(y=avg_accuracy, color='red', linestyle='--', linewidth=2, label=f'Average: {avg_accuracy:.3f}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xticks(tick_marks)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Per-class F1-score\n",
    "class_stats = []\n",
    "for i in range(52):\n",
    "    tp = cm[i, i]\n",
    "    fp = cm[:, i].sum() - tp\n",
    "    fn = cm[i, :].sum() - tp\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    class_stats.append({\n",
    "        'class': i,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'support': tp + fn\n",
    "    })\n",
    "class_stats_df = pd.DataFrame(class_stats)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars_f1 = plt.bar(classes, class_stats_df['f1_score'], color='orange', alpha=0.7, edgecolor='darkorange', linewidth=0.5)\n",
    "plt.title('Per-Class F1-Score', fontweight='bold')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "best_f1_class = class_stats_df['f1_score'].idxmax()\n",
    "worst_f1_class = class_stats_df['f1_score'].idxmin()\n",
    "bars_f1[best_f1_class].set_color('green')\n",
    "bars_f1[worst_f1_class].set_color('red')\n",
    "avg_f1 = class_stats_df['f1_score'].mean()\n",
    "plt.axhline(y=avg_f1, color='red', linestyle='--', linewidth=2, label=f'Average: {avg_f1:.3f}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xticks(tick_marks)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(f\"\\nConfusion Matrix Statistics:\")\n",
    "print(\"\")\n",
    "print(f\"Overall Accuracy: {np.trace(cm) / np.sum(cm):.4f}\")\n",
    "print(f\"Average Per-Class Recall: {avg_accuracy:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Performing Classes:\")\n",
    "print(\"\")\n",
    "top_5_recall = class_stats_df.nlargest(5, 'recall')\n",
    "for _, row in top_5_recall.iterrows():\n",
    "    print(f\"Class {int(row['class']):2d}: Recall={row['recall']:.3f}, F1={row['f1_score']:.3f}, Support={int(row['support'])}\")\n",
    "\n",
    "print(f\"\\nWorst Performing Classes:\")\n",
    "print(\"\")\n",
    "bottom_5_recall = class_stats_df.nsmallest(5, 'recall')\n",
    "for _, row in bottom_5_recall.iterrows():\n",
    "    print(f\"Class {int(row['class']):2d}: Recall={row['recall']:.3f}, F1={row['f1_score']:.3f}, Support={int(row['support'])}\")\n",
    "\n",
    "# Most confused class pairs\n",
    "print(f\"\\nMost Confused Class pairs:\")\n",
    "print(\"\")\n",
    "confused_pairs = []\n",
    "for i in range(52):\n",
    "    for j in range(52):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confused_pairs.append((i, j, cm[i, j]))\n",
    "\n",
    "confused_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "for i, (true_class, pred_class, count) in enumerate(confused_pairs[:10]):\n",
    "    print(f\"{i+1:2d}. Class {true_class:2d} → Class {pred_class:2d}: {count:4d} samples\")\n",
    "\n",
    "print(f\"\\nClass Distribution In Test Set:\")\n",
    "print(f\"=\"*32)\n",
    "unique_classes, class_counts = np.unique(all_y_true, return_counts=True)\n",
    "print(f\"Number of unique classes in test set: {len(unique_classes)}\")\n",
    "print(f\"Class distribution statistics:\")\n",
    "print(f\"   Min samples per class: {np.min(class_counts)}\")\n",
    "print(f\"   Max samples per class: {np.max(class_counts)}\")\n",
    "print(f\"   Mean samples per class: {np.mean(class_counts):.1f}\")\n",
    "print(f\"   Std samples per class: {np.std(class_counts):.1f}\")\n",
    "print(f\"   Class imbalance ratio: {np.max(class_counts) / np.min(class_counts):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab73bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUROC Curve for Multi-Class Classification (One-vs-Rest)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nAUROC Curve Analysis\")\n",
    "\n",
    "n_classes = 52\n",
    "\n",
    "# Collect all test data and predicted probabilities from all folds\n",
    "all_y_true = []\n",
    "all_y_score = []\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    fold_data = kfold_data[i]\n",
    "    X_test_fold = fold_data['X_test']\n",
    "    y_test_fold = fold_data['y_test']\n",
    "    y_pred_prob = analysis_model.predict(X_test_fold, verbose=0)\n",
    "    all_y_true.extend(y_test_fold)\n",
    "    all_y_score.append(y_pred_prob)\n",
    "\n",
    "all_y_true = np.array(all_y_true)\n",
    "all_y_score = np.vstack(all_y_score)\n",
    "\n",
    "# Binarize the labels for multi-class ROC\n",
    "y_true_bin = label_binarize(all_y_true, classes=np.arange(n_classes))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], all_y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for the five worst classes\n",
    "worst_classes = [40, 44, 38, 13, 36]    # Worst performing classes from last cell\n",
    "best_class = 20                         # Best performing class from last cell in comparison\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in worst_classes:\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, color='grey', label=f'Class {i}')\n",
    "# Plot best class in green\n",
    "plt.plot(fpr[best_class], tpr[best_class], lw=2, color='black', label=f'Class {best_class}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUROC Curves: Five Worst Classes (Grey) and Best Class (Black)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print mean and best AUROC\n",
    "mean_auc = np.mean(list(roc_auc.values()))\n",
    "best_auc = np.max(list(roc_auc.values()))\n",
    "print(f\"\\nMean AUROC across all classes: {mean_auc:.3f}\")\n",
    "print(f\"Best AUROC: {best_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e537b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUROC for Best and Five Worst Classes\")\n",
    "print(\"\")\n",
    "\n",
    "# Worst classes AUROC\n",
    "for i in worst_classes:\n",
    "    print(f\"Worst class (Class {i}) AUROC: {roc_auc[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Feature Importance Analysis\n",
    "print(\"\\nFeature Importance Analysis\")\n",
    "print(\"\")\n",
    "\n",
    "# Clear any SHAP interference and restart fresh\n",
    "import gc\n",
    "if 'explainer' in globals():\n",
    "    del explainer\n",
    "gc.collect()\n",
    "\n",
    "# Restart TensorFlow session to clear any SHAP interference\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Reload the model fresh to avoid any SHAP contamination\n",
    "print(\"Loading clean model for analysis...\")\n",
    "try:\n",
    "    clean_model = tf.keras.models.load_model('best_CNN_Model.keras')\n",
    "    print(\"Model loaded successfully\")\n",
    "except:\n",
    "    print(\"Using analysis_model from memory\")\n",
    "    clean_model = analysis_model\n",
    "\n",
    "# Select data for analysis\n",
    "n_samples_analysis = min(30, len(all_y_true))\n",
    "fold_data = kfold_data[0]\n",
    "X_analysis = fold_data['X_test'][:n_samples_analysis]\n",
    "y_analysis = fold_data['y_test'][:n_samples_analysis]\n",
    "\n",
    "print(f\"Analyzing {n_samples_analysis} samples\")\n",
    "print(f\"Input shape: {X_analysis.shape}\")\n",
    "\n",
    "# Method 1: Permutation Feature Importance\n",
    "print(\"\\n1. Computing permutation feature importance...\")\n",
    "\n",
    "def permutation_importance_analysis(model, X, y, n_repeats=3):\n",
    "    \"\"\"Compute permutation importance for each feature\"\"\"\n",
    "    # Get baseline predictions\n",
    "    baseline_predictions = model.predict(X, verbose=0)\n",
    "    baseline_accuracy = np.mean(np.argmax(baseline_predictions, axis=1) == y)\n",
    "    \n",
    "    importance_scores = np.zeros((X.shape[1], X.shape[2]))  # time_steps x channels\n",
    "    \n",
    "    for time_step in range(X.shape[1]):\n",
    "        for channel in range(X.shape[2]):\n",
    "            scores = []\n",
    "            for _ in range(n_repeats):\n",
    "                # Create a copy and permute this feature\n",
    "                X_permuted = X.copy()\n",
    "                np.random.shuffle(X_permuted[:, time_step, channel])\n",
    "                \n",
    "                # Get predictions with permuted feature\n",
    "                permuted_predictions = model.predict(X_permuted, verbose=0)\n",
    "                permuted_accuracy = np.mean(np.argmax(permuted_predictions, axis=1) == y)\n",
    "                \n",
    "                # Importance is the decrease in accuracy\n",
    "                importance = baseline_accuracy - permuted_accuracy\n",
    "                scores.append(importance)\n",
    "            \n",
    "            importance_scores[time_step, channel] = np.mean(scores)\n",
    "    \n",
    "    return importance_scores, baseline_accuracy\n",
    "\n",
    "perm_importance, baseline_acc = permutation_importance_analysis(clean_model, X_analysis, y_analysis)\n",
    "print(f\"Baseline accuracy: {baseline_acc:.4f}\")\n",
    "\n",
    "# Method 2: Occlusion Analysis\n",
    "print(\"2. Computing occlusion-based importance...\")\n",
    "\n",
    "def occlusion_analysis(model, X, y, occlusion_size=3):\n",
    "    \"\"\"Analyze feature importance by occluding regions\"\"\"\n",
    "    baseline_predictions = model.predict(X, verbose=0)\n",
    "    baseline_accuracy = np.mean(np.argmax(baseline_predictions, axis=1) == y)\n",
    "    \n",
    "    occlusion_scores = np.zeros((X.shape[1], X.shape[2]))\n",
    "    \n",
    "    for time_step in range(0, X.shape[1], occlusion_size):\n",
    "        for channel in range(X.shape[2]):\n",
    "            # Occlude this region\n",
    "            X_occluded = X.copy()\n",
    "            end_time = min(time_step + occlusion_size, X.shape[1])\n",
    "            X_occluded[:, time_step:end_time, channel] = 0\n",
    "            \n",
    "            # Get predictions with occluded feature\n",
    "            occluded_predictions = model.predict(X_occluded, verbose=0)\n",
    "            occluded_accuracy = np.mean(np.argmax(occluded_predictions, axis=1) == y)\n",
    "            \n",
    "            # Importance is the decrease in accuracy\n",
    "            importance = baseline_accuracy - occluded_accuracy\n",
    "            for t in range(time_step, end_time):\n",
    "                occlusion_scores[t, channel] = importance\n",
    "    \n",
    "    return occlusion_scores\n",
    "\n",
    "occlusion_importance = occlusion_analysis(clean_model, X_analysis, y_analysis)\n",
    "\n",
    "# Method 3: Variance-based Analysis\n",
    "print(\"3. Computing variance-based feature importance...\")\n",
    "\n",
    "def variance_analysis(X):\n",
    "    \"\"\"Analyze feature importance based on variance\"\"\"\n",
    "    # Normalize the data first\n",
    "    X_norm = (X - np.mean(X, axis=0)) / (np.std(X, axis=0) + 1e-8)\n",
    "    \n",
    "    # Compute variance across samples for each feature\n",
    "    feature_variance = np.var(X_norm, axis=0)\n",
    "    \n",
    "    return feature_variance\n",
    "\n",
    "variance_importance = variance_analysis(X_analysis)\n",
    "\n",
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Feature Importance Analysis - Multiple Methods', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Permutation importance by channel\n",
    "ax1 = axes[0, 0]\n",
    "channel_perm_importance = np.mean(perm_importance, axis=0)\n",
    "channels = np.arange(16) # change to 16 for NinaPro DB5 or 12 for NinaPro DB4\n",
    "\n",
    "bars1 = ax1.bar(channels, channel_perm_importance, color='steelblue', alpha=0.7, edgecolor='navy')\n",
    "ax1.set_title('Channel Importance (Permutation)', fontweight='bold')\n",
    "ax1.set_xlabel('EMG Channel')\n",
    "ax1.set_ylabel('Importance Score')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight top channels\n",
    "top_channels_perm = np.argsort(channel_perm_importance)[-3:]\n",
    "for ch in top_channels_perm:\n",
    "    bars1[ch].set_color('orange')\n",
    "\n",
    "# 2. Temporal importance (permutation)\n",
    "ax2 = axes[0, 1]\n",
    "temporal_perm_importance = np.mean(perm_importance, axis=1)\n",
    "time_steps = np.arange(WINDOW_SIZE)\n",
    "\n",
    "ax2.plot(time_steps, temporal_perm_importance, 'o-', color='darkgreen', linewidth=2, markersize=4)\n",
    "ax2.set_title('Temporal Importance (Permutation)', fontweight='bold')\n",
    "ax2.set_xlabel('Time Step')\n",
    "ax2.set_ylabel('Importance Score')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight top time steps\n",
    "top_timesteps_perm = np.argsort(temporal_perm_importance)[-5:]\n",
    "ax2.scatter(top_timesteps_perm, temporal_perm_importance[top_timesteps_perm], \n",
    "           color='red', s=60, zorder=5, label='Top 5 time steps')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Permutation importance heatmap\n",
    "ax3 = axes[0, 2]\n",
    "im1 = ax3.imshow(perm_importance.T, aspect='auto', cmap='RdYlBu_r', interpolation='nearest')\n",
    "ax3.set_title('Permutation Importance Heatmap', fontweight='bold')\n",
    "ax3.set_xlabel('Time Step')\n",
    "ax3.set_ylabel('EMG Channel')\n",
    "cbar1 = plt.colorbar(im1, ax=ax3, shrink=0.8)\n",
    "cbar1.set_label('Importance Score')\n",
    "\n",
    "# 4. Occlusion importance by channel\n",
    "ax4 = axes[1, 0]\n",
    "channel_occ_importance = np.mean(occlusion_importance, axis=0)\n",
    "\n",
    "bars2 = ax4.bar(channels, channel_occ_importance, color='purple', alpha=0.7, edgecolor='darkviolet')\n",
    "ax4.set_title('Channel Importance (Occlusion)', fontweight='bold')\n",
    "ax4.set_xlabel('EMG Channel')\n",
    "ax4.set_ylabel('Importance Score')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight top channels\n",
    "top_channels_occ = np.argsort(channel_occ_importance)[-3:]\n",
    "for ch in top_channels_occ:\n",
    "    bars2[ch].set_color('orange')\n",
    "\n",
    "# 5. Variance-based importance\n",
    "ax5 = axes[1, 1]\n",
    "channel_var_importance = np.mean(variance_importance, axis=0)\n",
    "\n",
    "bars3 = ax5.bar(channels, channel_var_importance, color='green', alpha=0.7, edgecolor='darkgreen')\n",
    "ax5.set_title('Channel Importance (Variance)', fontweight='bold')\n",
    "ax5.set_xlabel('EMG Channel')\n",
    "ax5.set_ylabel('Variance Score')\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight top channels\n",
    "top_channels_var = np.argsort(channel_var_importance)[-3:]\n",
    "for ch in top_channels_var:\n",
    "    bars3[ch].set_color('orange')\n",
    "\n",
    "# 6. Method comparison\n",
    "ax6 = axes[1, 2]\n",
    "\n",
    "# Normalize for comparison\n",
    "perm_norm = channel_perm_importance / np.max(np.abs(channel_perm_importance))\n",
    "occ_norm = channel_occ_importance / np.max(np.abs(channel_occ_importance))\n",
    "var_norm = channel_var_importance / np.max(channel_var_importance)\n",
    "\n",
    "width = 0.25\n",
    "x_pos = np.arange(len(channels))\n",
    "\n",
    "bars_comp1 = ax6.bar(x_pos - width, perm_norm, width, \n",
    "                    label='Permutation', color='steelblue', alpha=0.7)\n",
    "bars_comp2 = ax6.bar(x_pos, occ_norm, width,\n",
    "                    label='Occlusion', color='purple', alpha=0.7)\n",
    "bars_comp3 = ax6.bar(x_pos + width, var_norm, width,\n",
    "                    label='Variance', color='green', alpha=0.7)\n",
    "\n",
    "ax6.set_title('Method Comparison (Normalized)', fontweight='bold')\n",
    "ax6.set_xlabel('EMG Channel')\n",
    "ax6.set_ylabel('Normalized Importance')\n",
    "ax6.set_xticks(x_pos)\n",
    "ax6.set_xticklabels(channels)\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed analysis\n",
    "print(f\"\\nFeature Importance Analysis Summary\")\n",
    "print(\"\")\n",
    "\n",
    "print(f\"\\nMost Important Channels\")\n",
    "print(\"\")\n",
    "print(\"Permutation Method:\")\n",
    "for i, ch in enumerate(reversed(top_channels_perm)):\n",
    "    print(f\"  {i+1}. Channel {ch:2d}: Score = {channel_perm_importance[ch]:.6f}\")\n",
    "\n",
    "print(\"\\nOcclusion Method:\")\n",
    "for i, ch in enumerate(reversed(top_channels_occ)):\n",
    "    print(f\"  {i+1}. Channel {ch:2d}: Score = {channel_occ_importance[ch]:.6f}\")\n",
    "\n",
    "print(\"\\nVariance Method:\")\n",
    "for i, ch in enumerate(reversed(top_channels_var)):\n",
    "    print(f\"  {i+1}. Channel {ch:2d}: Score = {channel_var_importance[ch]:.6f}\")\n",
    "\n",
    "print(f\"\\nMost Important Time Steps:\")\n",
    "print(\"\")\n",
    "for i, ts in enumerate(reversed(top_timesteps_perm)):\n",
    "    print(f\"  {i+1}. Time step {ts:2d}: Score = {temporal_perm_importance[ts]:.6f}\")\n",
    "\n",
    "print(f\"\\nTemporal Pattern Analysis:\")\n",
    "print(\"\")\n",
    "early_importance = np.mean(temporal_perm_importance[:WINDOW_SIZE//3])\n",
    "middle_importance = np.mean(temporal_perm_importance[WINDOW_SIZE//3:2*WINDOW_SIZE//3])\n",
    "late_importance = np.mean(temporal_perm_importance[2*WINDOW_SIZE//3:])\n",
    "\n",
    "print(f\"First Exercise (first 1/3):   {early_importance:.6f}\")\n",
    "print(f\"Second Exercise (middle 1/3): {middle_importance:.6f}\")\n",
    "print(f\"Third Exercise (last 1/3):     {late_importance:.6f}\")\n",
    "\n",
    "if early_importance > middle_importance and early_importance > late_importance:\n",
    "    print(\"→ Model focuses most on First muscle activation patterns\")\n",
    "elif late_importance > early_importance and late_importance > middle_importance:\n",
    "    print(\"→ Model focuses most on Third muscle activation patterns\")\n",
    "else:\n",
    "    print(\"→ Model focuses most on Second muscle activation patterns\")\n",
    "\n",
    "print(f\"\\nChannel Group Analysis:\")\n",
    "print(\"\")\n",
    "proximal_channels = [0, 1, 2, 3]\n",
    "middle_channels = [4, 5, 6, 7, 8, 9, 10, 11]\n",
    "distal_channels = [12, 13, 14, 15]\n",
    "\n",
    "proximal_importance = np.mean(channel_perm_importance[proximal_channels])\n",
    "middle_group_importance = np.mean(channel_perm_importance[middle_channels])\n",
    "distal_importance = np.mean(channel_perm_importance[distal_channels])\n",
    "\n",
    "print(f\"Proximal muscles (channels 0-3):   {proximal_importance:.6f}\")\n",
    "print(f\"Middle muscles (channels 4-11):    {middle_group_importance:.6f}\")\n",
    "print(f\"Distal muscles (channels 12-15):   {distal_importance:.6f}\")\n",
    "\n",
    "max_group = max(proximal_importance, middle_group_importance, distal_importance)\n",
    "if max_group == proximal_importance:\n",
    "    print(\"→ Model relies most on PROXIMAL muscle activity\")\n",
    "elif max_group == distal_importance:\n",
    "    print(\"→ Model relies most on DISTAL muscle activity\")\n",
    "else:\n",
    "    print(\"→ Model relies most on MIDDLE muscle groups\")\n",
    "\n",
    "print(f\"\\nMethod Consistency:\")\n",
    "print(\"\")\n",
    "# Check consistency between methods\n",
    "corr_perm_occ = np.corrcoef(perm_norm, occ_norm)[0, 1]\n",
    "corr_perm_var = np.corrcoef(perm_norm, var_norm)[0, 1]\n",
    "corr_occ_var = np.corrcoef(occ_norm, var_norm)[0, 1]\n",
    "\n",
    "print(f\"Permutation vs Occlusion:  {corr_perm_occ:.3f}\")\n",
    "print(f\"Permutation vs Variance:   {corr_perm_var:.3f}\")\n",
    "print(f\"Occlusion vs Variance:     {corr_occ_var:.3f}\")\n",
    "\n",
    "avg_correlation = np.mean([corr_perm_occ, corr_perm_var, corr_occ_var])\n",
    "print(f\"Average correlation:       {avg_correlation:.3f}\")\n",
    "\n",
    "if avg_correlation > 0.7:\n",
    "    print(\"→ High consistency between methods\")\n",
    "elif avg_correlation > 0.4:\n",
    "    print(\"→ Moderate consistency between methods\")\n",
    "else:\n",
    "    print(\"→ Low consistency between methods - results may be method-dependent\")\n",
    "\n",
    "print(\"\\nFeature importance analysis complete!\")\n",
    "print(\"- Permutation importance shows which features are most critical for predictions\")\n",
    "print(\"- Occlusion analysis reveals spatial dependencies in the model\")\n",
    "print(\"- Variance analysis identifies the most discriminative features\")\n",
    "print(\"- Multiple methods provide robust and reliable importance estimates\")\n",
    "print(\"- These insights can guide electrode placement and feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c80a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-wise Training Contribution Analysis\n",
    "print(\"\\nClass-Wise Training Contribution Analysis\")\n",
    "print(\"\")\n",
    "\n",
    "# Analyze how each class contributed to model training across folds\n",
    "print(\"Analyzing class contributions across all folds...\")\n",
    "\n",
    "# 1. Collect class-wise data from all folds\n",
    "class_contributions = {}\n",
    "class_sample_counts = {}\n",
    "class_fold_performance = {}\n",
    "\n",
    "for fold_idx, fold_data in enumerate(kfold_data):\n",
    "    X_train, X_test = fold_data['X_train'], fold_data['X_test']\n",
    "    y_train, y_test = fold_data['y_train'], fold_data['y_test']\n",
    "    \n",
    "    # Count samples per class in training set\n",
    "    train_class_counts = np.bincount(y_train, minlength=52)\n",
    "    test_class_counts = np.bincount(y_test, minlength=52)\n",
    "    \n",
    "    for class_id in range(52):\n",
    "        if class_id not in class_contributions:\n",
    "            class_contributions[class_id] = {\n",
    "                'train_samples': [],\n",
    "                'test_samples': [],\n",
    "                'fold_performance': [],\n",
    "                'total_train_samples': 0,\n",
    "                'total_test_samples': 0\n",
    "            }\n",
    "        \n",
    "        class_contributions[class_id]['train_samples'].append(train_class_counts[class_id])\n",
    "        class_contributions[class_id]['test_samples'].append(test_class_counts[class_id])\n",
    "        class_contributions[class_id]['total_train_samples'] += train_class_counts[class_id]\n",
    "        class_contributions[class_id]['total_test_samples'] += test_class_counts[class_id]\n",
    "\n",
    "# 2. Calculate class-wise performance metrics\n",
    "class_performance_metrics = {}\n",
    "for class_id in range(52):\n",
    "    # Get predictions for this class\n",
    "    class_mask = (all_y_true == class_id)\n",
    "    if np.sum(class_mask) > 0:\n",
    "        class_predictions = all_y_pred[class_mask]\n",
    "        class_accuracy = np.mean(class_predictions == class_id)\n",
    "        \n",
    "        # Calculate precision and recall from confusion matrix\n",
    "        tp = np.sum((all_y_true == class_id) & (all_y_pred == class_id))\n",
    "        fp = np.sum((all_y_true != class_id) & (all_y_pred == class_id))\n",
    "        fn = np.sum((all_y_true == class_id) & (all_y_pred != class_id))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        class_performance_metrics[class_id] = {\n",
    "            'accuracy': class_accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'total_samples': np.sum(class_mask),\n",
    "            'correct_predictions': tp\n",
    "        }\n",
    "    else:\n",
    "        class_performance_metrics[class_id] = {\n",
    "            'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0,\n",
    "            'total_samples': 0, 'correct_predictions': 0\n",
    "        }\n",
    "\n",
    "# 3. Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 18))\n",
    "fig.suptitle('Class-wise Training Contribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 3.1 Training sample distribution across classes\n",
    "ax1 = axes[0, 0]\n",
    "class_ids = list(range(52))\n",
    "total_train_samples = [class_contributions[i]['total_train_samples'] for i in class_ids]\n",
    "\n",
    "bars1 = ax1.bar(class_ids, total_train_samples, color='steelblue', alpha=0.7, edgecolor='navy')\n",
    "ax1.set_title('Training Samples per Class', fontweight='bold')\n",
    "ax1.set_xlabel('Movement Class')\n",
    "ax1.set_ylabel('Total Training Samples')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight classes with most and least samples\n",
    "max_samples_class = np.argmax(total_train_samples)\n",
    "min_samples_class = np.argmax([s for s in total_train_samples if s > 0])  # Non-zero minimum\n",
    "bars1[max_samples_class].set_color('green')\n",
    "if total_train_samples[min_samples_class] > 0:\n",
    "    bars1[min_samples_class].set_color('red')\n",
    "\n",
    "# 3.2 Class performance vs sample count\n",
    "ax2 = axes[0, 1]\n",
    "class_f1_scores = [class_performance_metrics[i]['f1_score'] for i in class_ids]\n",
    "sample_sizes = [class_performance_metrics[i]['total_samples'] for i in class_ids]\n",
    "\n",
    "# Only plot classes with samples > 0\n",
    "valid_classes = [(i, f1, samples) for i, f1, samples in zip(class_ids, class_f1_scores, sample_sizes) if samples > 0]\n",
    "if valid_classes:\n",
    "    valid_class_ids, valid_f1s, valid_samples = zip(*valid_classes)\n",
    "    \n",
    "    scatter = ax2.scatter(valid_samples, valid_f1s, c=valid_class_ids, cmap='viridis', \n",
    "                         s=60, alpha=0.7, edgecolors='black')\n",
    "    ax2.set_title('Class Performance vs Sample Count', fontweight='bold')\n",
    "    ax2.set_xlabel('Total Test Samples')\n",
    "    ax2.set_ylabel('F1 Score')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax2)\n",
    "    cbar.set_label('Class ID')\n",
    "    \n",
    "    # Add trend line\n",
    "    if len(valid_samples) > 1:\n",
    "        z = np.polyfit(valid_samples, valid_f1s, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax2.plot(valid_samples, p(valid_samples), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "# 3.3 Class-wise recall distribution\n",
    "ax3 = axes[1, 0]\n",
    "class_recalls = [class_performance_metrics[i]['recall'] for i in class_ids]\n",
    "\n",
    "bars3 = ax3.bar(class_ids, class_recalls, color='orange', alpha=0.7, edgecolor='darkorange')\n",
    "ax3.set_title('Recall per Class', fontweight='bold')\n",
    "ax3.set_xlabel('Movement Class')\n",
    "ax3.set_ylabel('Recall')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "ax3.axhline(y=np.mean(class_recalls), color='red', linestyle='--', linewidth=2, label=f'Mean Recall: {np.mean(class_recalls):.3f}')\n",
    "ax3.legend()\n",
    "\n",
    "# Highlight best and worst performing classes\n",
    "best_recall_class = np.argmax(class_recalls)\n",
    "worst_recall_class = np.argmin([r for r in class_recalls if r >= 0])\n",
    "bars3[best_recall_class].set_color('green')\n",
    "bars3[worst_recall_class].set_color('red')\n",
    "\n",
    "# 3.4 Training sample variance across folds\n",
    "ax4 = axes[1, 1]\n",
    "sample_variances = []\n",
    "sample_means = []\n",
    "\n",
    "for class_id in class_ids:\n",
    "    train_samples = class_contributions[class_id]['train_samples']\n",
    "    if any(s > 0 for s in train_samples):\n",
    "        sample_variances.append(np.var(train_samples))\n",
    "        sample_means.append(np.mean(train_samples))\n",
    "    else:\n",
    "        sample_variances.append(0)\n",
    "        sample_means.append(0)\n",
    "\n",
    "bars4 = ax4.bar(class_ids, sample_variances, color='purple', alpha=0.7, edgecolor='darkviolet')\n",
    "ax4.set_title('Training Sample Variance Across Folds', fontweight='bold')\n",
    "ax4.set_xlabel('Movement Class')\n",
    "ax4.set_ylabel('Sample Count Variance')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight classes with highest variance (inconsistent across folds)\n",
    "high_variance_classes = np.argsort(sample_variances)[-3:]\n",
    "for cls in high_variance_classes:\n",
    "    if sample_variances[cls] > 0:\n",
    "        bars4[cls].set_color('red')\n",
    "\n",
    "# 3.5 Class contribution efficiency (Performance per training sample)\n",
    "ax5 = axes[2, 0]\n",
    "efficiency_scores = []\n",
    "for class_id in class_ids:\n",
    "    total_train = class_contributions[class_id]['total_train_samples']\n",
    "    f1_score = class_performance_metrics[class_id]['f1_score']\n",
    "    \n",
    "    if total_train > 0:\n",
    "        efficiency = f1_score / (total_train / 1000)  # F1 per 1000 training samples\n",
    "    else:\n",
    "        efficiency = 0\n",
    "    efficiency_scores.append(efficiency)\n",
    "\n",
    "bars5 = ax5.bar(class_ids, efficiency_scores, color='green', alpha=0.7, edgecolor='darkgreen')\n",
    "ax5.set_title('Training Efficiency (F1 Score per 1000 Training Samples)', fontweight='bold')\n",
    "ax5.set_xlabel('Movement Class')\n",
    "ax5.set_ylabel('Efficiency Score')\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight most and least efficient classes\n",
    "if any(e > 0 for e in efficiency_scores):\n",
    "    most_efficient_class = np.argmax(efficiency_scores)\n",
    "    bars5[most_efficient_class].set_color('gold')\n",
    "\n",
    "# 3.6 Class balance analysis (Training vs Test sample ratio)\n",
    "ax6 = axes[2, 1]\n",
    "balance_ratios = []\n",
    "for class_id in class_ids:\n",
    "    total_train = class_contributions[class_id]['total_train_samples']\n",
    "    total_test = class_contributions[class_id]['total_test_samples']\n",
    "    \n",
    "    if total_test > 0:\n",
    "        ratio = total_train / total_test\n",
    "    else:\n",
    "        ratio = 0\n",
    "    balance_ratios.append(ratio)\n",
    "\n",
    "bars6 = ax6.bar(class_ids, balance_ratios, color='teal', alpha=0.7, edgecolor='darkcyan')\n",
    "ax6.set_title('Train/Test Sample Ratio per Class', fontweight='bold')\n",
    "ax6.set_xlabel('Movement Class')\n",
    "ax6.set_ylabel('Train/Test Ratio')\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "ax6.axhline(y=np.mean([r for r in balance_ratios if r > 0]), color='red', linestyle='--', \n",
    "           linewidth=2, label=f'Mean Ratio: {np.mean([r for r in balance_ratios if r > 0]):.2f}')\n",
    "ax6.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Detailed analysis and insights\n",
    "print(f\"\\nClass Contribution Analysis Summary\")\n",
    "print(\"\")\n",
    "\n",
    "# Top and bottom performers\n",
    "valid_f1_scores = [(i, score) for i, score in enumerate(class_f1_scores) if score > 0]\n",
    "if valid_f1_scores:\n",
    "    sorted_by_f1 = sorted(valid_f1_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTop 5 Performing Classes (by F1 Score):\")\n",
    "    print(\"\")\n",
    "    for i, (class_id, f1_score) in enumerate(sorted_by_f1[:5]):\n",
    "        train_samples = class_contributions[class_id]['total_train_samples']\n",
    "        test_samples = class_contributions[class_id]['total_test_samples']\n",
    "        print(f\"  {i+1}. Class {class_id:2d}: F1={f1_score:.3f}, Train={train_samples:,}, Test={test_samples:,}\")\n",
    "\n",
    "    print(f\"\\nBottom 5 Performing Classes (by F1 Score):\")\n",
    "    print(f\"=\"*42)\n",
    "    for i, (class_id, f1_score) in enumerate(sorted_by_f1[-5:]):\n",
    "        train_samples = class_contributions[class_id]['total_train_samples']\n",
    "        test_samples = class_contributions[class_id]['total_test_samples']\n",
    "        print(f\"  {i+1}. Class {class_id:2d}: F1={f1_score:.3f}, Train={train_samples:,}, Test={test_samples:,}\")\n",
    "\n",
    "# Sample distribution insights\n",
    "total_samples_all_classes = sum(total_train_samples)\n",
    "print(f\"\\nSample Distribution Insights:\")\n",
    "print(\"\")\n",
    "print(f\"• Total training samples: {total_samples_all_classes:,}\")\n",
    "print(f\"• Average samples per class: {total_samples_all_classes/52:,.0f}\")\n",
    "print(f\"• Most represented class: {max_samples_class} ({max(total_train_samples):,} samples)\")\n",
    "\n",
    "non_zero_samples = [s for s in total_train_samples if s > 0]\n",
    "if non_zero_samples:\n",
    "    print(f\"• Least represented class (non-zero): {total_train_samples.index(min(non_zero_samples))} ({min(non_zero_samples):,} samples)\")\n",
    "    print(f\"• Sample distribution std: {np.std(non_zero_samples):,.0f}\")\n",
    "\n",
    "# Training efficiency insights\n",
    "valid_efficiency = [(i, eff) for i, eff in enumerate(efficiency_scores) if eff > 0]\n",
    "if valid_efficiency:\n",
    "    most_efficient = max(valid_efficiency, key=lambda x: x[1])\n",
    "    print(f\"\\nTraining efficiency insight:\")\n",
    "    print(\"\")\n",
    "    print(f\"• Most efficient class: {most_efficient[0]} (F1={class_performance_metrics[most_efficient[0]]['f1_score']:.3f} per 1000 samples)\")\n",
    "    print(f\"• Average efficiency: {np.mean([eff for _, eff in valid_efficiency]):.3f}\")\n",
    "\n",
    "# Balance analysis\n",
    "valid_ratios = [r for r in balance_ratios if r > 0]\n",
    "if valid_ratios:\n",
    "    print(f\"\\nTrain/Test Balance Insight:\")\n",
    "    print(\"\")\n",
    "    print(f\"• Average train/test ratio: {np.mean(valid_ratios):.2f}\")\n",
    "    print(f\"• Most balanced class: {balance_ratios.index(min(valid_ratios, key=lambda x: abs(x - np.mean(valid_ratios))))} (ratio: {min(valid_ratios, key=lambda x: abs(x - np.mean(valid_ratios))):.2f})\")\n",
    "    print(f\"• Ratio standard deviation: {np.std(valid_ratios):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Class Grouping and Training Progression Analysis\n",
    "print(\"\\nAdvanced Class Grouping Analysis\")\n",
    "print(\"\")\n",
    "\n",
    "# Define meaningful class groups based on movement types (adjust based on the dataset)\n",
    "class_groups = {\n",
    "    'Exercise A': list(range(0, 12)),\n",
    "    'Exercise B': list(range(12, 39)),\n",
    "    'Exercise C': list(range(39, 52)),\n",
    "}\n",
    "\n",
    "# Calculate group-wise statistics\n",
    "group_stats = {}\n",
    "for group_name, class_list in class_groups.items():\n",
    "    group_train_samples = sum(class_contributions[cls]['total_train_samples'] for cls in class_list)\n",
    "    group_test_samples = sum(class_contributions[cls]['total_test_samples'] for cls in class_list)\n",
    "    \n",
    "    # Calculate average performance for the group\n",
    "    group_f1_scores = [class_performance_metrics[cls]['f1_score'] for cls in class_list \n",
    "                      if class_performance_metrics[cls]['total_samples'] > 0]\n",
    "    group_recalls = [class_performance_metrics[cls]['recall'] for cls in class_list \n",
    "                    if class_performance_metrics[cls]['total_samples'] > 0]\n",
    "    \n",
    "    group_stats[group_name] = {\n",
    "        'train_samples': group_train_samples,\n",
    "        'test_samples': group_test_samples,\n",
    "        'avg_f1': np.mean(group_f1_scores) if group_f1_scores else 0,\n",
    "        'avg_recall': np.mean(group_recalls) if group_recalls else 0,\n",
    "        'num_classes': len(class_list),\n",
    "        'active_classes': len(group_f1_scores)  # Classes with samples > 0\n",
    "    }\n",
    "\n",
    "# Sample distribution by Exercise\n",
    "group_names = list(group_stats.keys())\n",
    "group_train_samples = [group_stats[name]['train_samples'] for name in group_names]\n",
    "group_test_samples = [group_stats[name]['test_samples'] for name in group_names]\n",
    "\n",
    "x_pos = np.arange(len(group_names))\n",
    "width = 0.35\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "bars1 = ax1.bar(x_pos - width/2, group_train_samples, width, label='Training', color='#2d2d2d', alpha=0.8)\n",
    "bars2 = ax1.bar(x_pos + width/2, group_test_samples, width, label='Testing', color='#a8a8a8', alpha=0.8)\n",
    "\n",
    "ax1.set_title('Sample Distribution by Exercise', fontweight='bold')\n",
    "ax1.set_xlabel('Exercise')\n",
    "ax1.set_ylabel('Number of Samples')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(group_names, rotation=0, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (train, test) in enumerate(zip(group_train_samples, group_test_samples)):\n",
    "    ax1.text(i - width/2, train + 50, f'{train:,}', ha='center', va='bottom', fontsize=9)\n",
    "    ax1.text(i + width/2, test + 50, f'{test:,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (train, test) in enumerate(zip(group_train_samples, group_test_samples)):\n",
    "    ax1.text(i - width/2, train + 50, f'{train:,}', ha='center', va='bottom', fontsize=9)\n",
    "    ax1.text(i + width/2, test + 50, f'{test:,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance by Exercise\n",
    "group_f1_scores = [group_stats[name]['avg_f1'] for name in group_names]\n",
    "group_recall_scores = [group_stats[name]['avg_recall'] for name in group_names]\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "bars3 = ax2.bar(x_pos - width/2, group_f1_scores, width, label='F1 Score', color='#2d2d2d', alpha=0.7)\n",
    "bars4 = ax2.bar(x_pos + width/2, group_recall_scores, width, label='Recall', color='#a8a8a8', alpha=0.7)\n",
    "\n",
    "ax2.set_title('Average Performance by Exercise', fontweight='bold')\n",
    "ax2.set_xlabel('Exercise')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(group_names, rotation=0, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.set_ylim(0, max(max(group_f1_scores), max(group_recall_scores)) * 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed group analysis results\n",
    "print(f\"\\nExercise Analysis Results\")\n",
    "print(\"\")\n",
    "\n",
    "for group_name in group_names:\n",
    "    stats = group_stats[group_name]\n",
    "    efficiency = stats['avg_f1'] / (stats['train_samples'] / 1000) if stats['train_samples'] > 0 else 0\n",
    "    coverage = stats['active_classes'] / stats['num_classes']\n",
    "    \n",
    "    print(f\"\\n{group_name.upper()}:\")\n",
    "    print(f\"  • Training samples: {stats['train_samples']:,}\")\n",
    "    print(f\"  • Test samples: {stats['test_samples']:,}\")\n",
    "    print(f\"  • Average F1 score: {stats['avg_f1']:.3f}\")\n",
    "    print(f\"  • Average recall: {stats['avg_recall']:.3f}\")\n",
    "    print(f\"  • Class coverage: {coverage:.1%} ({stats['active_classes']}/{stats['num_classes']} classes)\")\n",
    "    print(f\"  • Training efficiency: {efficiency:.4f}\")\n",
    "\n",
    "# Overall insights\n",
    "print(f\"\\nKey Exercise Insights\")\n",
    "print(\"\")\n",
    "\n",
    "# Best performing group\n",
    "best_f1_group = group_names[np.argmax(group_f1_scores)]\n",
    "best_efficiency_group = group_names[np.argmax([group_stats[name]['avg_f1'] / (group_stats[name]['train_samples'] / 1000) if group_stats[name]['train_samples'] > 0 else 0 for name in group_names])]\n",
    "most_data_group = group_names[np.argmax(group_train_samples)]\n",
    "\n",
    "print(f\"• Best performing group (F1): {best_f1_group} ({max(group_f1_scores):.3f})\")\n",
    "print(f\"• Most efficient group: {best_efficiency_group} ({max([group_stats[name]['avg_f1'] / (group_stats[name]['train_samples'] / 1000) if group_stats[name]['train_samples'] > 0 else 0 for name in group_names]):.4f})\")\n",
    "print(f\"• Most represented group: {most_data_group} ({max(group_train_samples):,} samples)\")\n",
    "\n",
    "# Coverage analysis\n",
    "avg_coverage = np.mean([stats['active_classes'] / stats['num_classes'] for stats in group_stats.values()])\n",
    "print(f\"• Average class coverage: {avg_coverage:.1%}\")\n",
    "\n",
    "if avg_coverage < 0.8:\n",
    "    print(\"  → Low coverage suggests many movement classes are underrepresented\")\n",
    "else:\n",
    "    print(\"  → Good coverage across movement types\")\n",
    "\n",
    "# Data balance analysis\n",
    "sample_counts = [group_stats[name]['train_samples'] for name in group_names]\n",
    "sample_std = np.std(sample_counts)\n",
    "sample_mean = np.mean(sample_counts)\n",
    "cv = sample_std / sample_mean if sample_mean > 0 else 0\n",
    "\n",
    "print(f\"• Data balance (CV): {cv:.2f}\")\n",
    "if cv > 0.5:\n",
    "    print(\"  → High variability in group representation\")\n",
    "elif cv > 0.3:\n",
    "    print(\"  → Moderate variability in group representation\")\n",
    "else:\n",
    "    print(\"  → Well-balanced representation across groups\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
